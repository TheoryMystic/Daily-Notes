* TODO [#A] 3D Math Primer :GameMath:
** Chapter 1 Cartesian Coordinate Systems[笛卡尔坐标系]
   3D math is all about measuring *locations*, *distances* and *angles* precisely and
   mathematically in 3D space.
   3D数学是关于如何在3维空间中精确测量 *位置*, *距离* 和 *角度* 的学科.

*** 1.1 1D Mathematics[1D数学]
    natural numbers[自然数]  
    --> A numbers line for the natural numbers[数轴]
    --> negative numbers[负数] 
    --> fractional numbers[分数]  
    --> rational numbers[有理数]
    --> real numbers[实数] [fn:real_number]
    --> discrete mathematics[离散数学] (study of natural numbers and integers)
    --> continuous mathematics[连续数学] (study of real numbers)

    _The First Law of Computer Graphics_
    If it _looks_ right, it _is_ right.

*** 1.2 2D Cartesian Space[2D笛卡尔空间]
    *origin*[原点]  --> 坐标(0,0)
    *axis*[轴] --> 穿过原点并且互相 *垂直*[perpendicular]的直线.
    *Cartesian coordinates*[笛卡尔坐标系] --> 由两个 *点* 来指明
    一个 *位置*[location].
    *signed distance*[有符号距离] --> 表示坐标点的x,y值分别到y,x轴
    的距离.(根据方向判断正负)

*** 1.3 3D Cartesian Space[3D笛卡尔空间]
    *Plane*[平面],就是由两条不平行的线张成的空间.
    与2D坐标系不同,3D笛卡尔空间的x,y,z轴并没有标准的定义.
    在2D坐标系中,x轴正方向向右,y轴正方向向上.
    而在3D笛卡尔空间中,指定了两种x,y,z轴位置的方法.
    一个是 *左手坐标系*[Left-handed],一个是 *右手坐标系*[Right-handed].
    在标准3D坐标系中,当:
    x -> 右 y ->上 z-> 外   -----> 左手坐标系
    x -> 右 y ->上 z-> 里   -----> 右手坐标系
    判断任意坐标系是左手还是右手时,将该坐标系旋转到标准坐标系,再根据z轴指向确定
    具体是左手还是右手坐标系.
        
*** 1.4 Odds and Ends[其他东西]
    *Summation Notation*[连加] -->  Σ
    *Product Notation*[连乘] -->  ∏
    *Interval Notation* [区间] -->  [a,b]   (a,b]   (a,b)
**** Angles,Degrees,and Radians[角,角度与弧度]
     *angle* --> an angle measures an amount of rotation in the plane.
     角表示的是 _对平面上旋转大小的度量_. 通常用希腊文θ表示.
     角有两种 *单位*[units],一种是 *degree*[角度°],另一种是 *radians*[弧度rad].
     πrad = 180°, 
     1 rad = (180/π)° , 1° = (π/180)rad.
**** Trig Functions[三角函数]
     以原点o(0,0)为圆心,做半径为1的单位圆.
     在单位圆上的点坐标为(x,y),作如下定义:
     sinθ = x/1 = x;
     cosθ = y/1 = y;
     tanθ = x/y;
     cscθ = 1/sinθ = 1/x;
     secθ = 1/cosθ = 1/y;
     cotθ = 1/tanθ = y/x;

     由勾股定理,有 x^2 + y^2 = 1 ---> sin^2θ + cos^2θ = 1;
     同理,有 1+tan^2θ = sec^2θ, 1+cot^2θ = csc^2θ;
          
***** Trig Identities[三角恒等式]
      同时,由单位圆几何图像可知,
      sin(-θ) = -x/1 = -x = -sinθ;
      cos(-θ) = y/1 = y = cosθ;
      tan(-θ) = -x/y = -tanθ;

      sin(π/2-θ) = cosθ;
      cos(π/2-θ) = sinθ;
      tan(π/2-θ) = cosθ/sinθ = cotθ;

      由向量点积 a.b = |a| |b| cosθ可得:
      cos(a+b) = cosacosb - sinasinb;
      cos(a-b) = cosacosb + sinasinb;
      sin(a+b) = sinacosb + cosasinb;
      sin(a-b) = sinacosb - cosasinb;
      tan(a+b) = (tana+tanb) / (1 - tanatanb);
      tan(a-b) = (tana -tanb) / (1 + tanatanb);
          
      若 θa = θb,则有:
      (sin2θ) = 2sinθcosθ;
      (cos2θ) = cos^2θ-sin^2θ = 1 - 2sin^2θ = 2cos^2θ - 1;
      (tan2θ) = (2tanθ) / (1 - tan^2θ);

      *law of sines*[sin法则] 和 *law of cosines*[cos法则]
      SinA/a = SinB/b = SinC/c;
      a^2 = b^2 + c^2 - 2bc cosA;
      b^2 = a^2 + c^2 - 2ac cosB;
      c^2 = a^2 + b^2 - 2ab cosC;
** Chapter 2 Vectors[向量]
   vector在数学和物理上具有不同的含义.
   在数学上,vector就是 *数的集合*[list of numbers].
   而在物理上,vector表示 _同时具有大小[magnitude]和方向[direction]的量[quantity]_.

*** 2.1 Mathematical Definition of Vector[向量的数学定义]
    在讨论vector的时候,我们需要明白vector[向量]与 *scalar*[标量]的区别.
    The *dimension*[维度] of a vector tells how many numbers the vector contains.
    vector有几个维度就包括了几个量.
    而scalar可以看成是1维的vector.也就是只包含了单个量的vector.
    至此,我们将引入两个新的概念:
    - *row vector*[行向量]  ---> [1,2,3]
    - *column vector*[列向量] --->  [1]
      [2]
      [3]
*** 2.2 Geometric Definition of Vector [vector的几何定义]
    vector表示 _同时具有大小[magnitude]和方向[direction]的线段[line segment]_.
    vector有 *头*[head] 和 *尾*[tail],头表示 *结束*[ends]的位置,尾表示 *开始*[starts]的位置.
*** 2.3 Vector as a Sequence of Displacements [vector-作为一系列的位移]
    *Displacements*[位移],表示物体的位置变化,定义为 _由初位置到末位置的有向线段_.
    由定义可知,位移是一个vector.
    而在3D向量中,我们通常把向量的位置分解成x,y,z三个位移量.分别表示该向量到三个
    轴的 *有符号距离*[signed distance].
*** 2.4 The Zero Vector [零向量]
    定义:zero vector 是每个维度的值都为0的向量. --> [0,0,0]
    那么零向量到底有什么用?
    我们知道每个向量的值都表示了位移位置的变化,零向量则意味着 _没有发生位移_.
*** 2.5 Vectors VS Points
    *向量*[vector] 表示物体的 *位移*[displacement],
    *点*[points]表示物体的位置.
**** Relative Positions[相对位置]
     所谓 *相对位置*,就是说,一个物体的位置一定是以某个坐标为原点,通过计算原点和物体的距离
     来确定的.
*** 2.6 Unit Vectors [单位向量]
    Unit vector  <-->  normalized vector <--> normals[法线]
    因为有些时候我们只想要知道 _向量的方向_,而不管它的 _大小_,由此就产生了 *Unit Vector*.
    *Unit vector*,就是模为1的矢量.

    而单词 *normal* 通常还有另一层含义: *perpendicular*[正交],表示垂直.
    当我们说 *normal vector* 的时候,其实是在说这个 *vector* 与另外的什么东西垂直.

    When this book refers to a vector as a *normal*, it means _a unit vector perpendicular to_
    _something else_.
    
    最后总结如下,一个 *normalized* vector 总有 *unit length*,但是一个 *normal* vector 表示的是
    一个 1) *垂直*[perpendicular] 于什么东西且 2)通常有 *单位长度*[unit length] 的vector.

    $\hat{v} = \frac{v}{|v|}$
    e.g
    [15 -3] / |[15 -3]| = [15 -3] / sqrt(15^2,-3^2) = [15 -3] / sqrt(225+9) = [15 -3] / sqrt(234)

*** 2.7 Vector Dot Product [向量点积]
    在向量的乘法中,除了 *向量*[vector] 与 *标量*[scalar] 相乘,还有向量与向量的乘法.
    而向量乘法分为两种,一种叫做 *点积*[dot product] , 一种叫做 *叉积*[cross product].
    点积在游戏编程中的使用无处不在,从 *图形学*[graphics] 到 *模拟*[simulation],或者是
    AI,都随处可见.
    
    dot product formula
    $a \cdot b = \sum_{i=1}^n ai$
    
**** Geometric Interpretation[几何解释]
     关于点积有两种几何解释,
     - The dot product a · b is equal to the signed length of the projection of b onto any line 
       parallel to a, multiplied by the length of a.
       点积结果是向量a到另一个向量b的 *投影*[projection]再乘以a的模.
       a . b = projb(a) 乘 |a|
       *投影*,就是指 1)在光线垂直射下来的某个平面的 2)某个物体的 *影子*[shadow].
       也可以说, *投影* 是 _二维到一维的_ *线性变换*[linear transformation].

       *线性*[linear] --> 任意一组 _共线_ 的 _等距离分布_ 的点在变换后依然保持 _共线_
       且 _等距离分布_ , 则说明这个变换是 *线性* 的.

       任何一个从二维到一维的线性变换,其效果等价于 _与向量(a,b)做点乘_,其中a和b为
       两个 *基向量* 被变换到的位置.
        
     - 用三角函数来解释,重点在于vector之间的 *夹角*(angle between the vectors)
       $cos\theta = \frac {\hat{a} \cdot \hat{b}} {1} = \hat{a} \cdot \hat{b}$
       $a \cdot b = |a| |b| cos\theta$
**** Summarize[总结]
     - The dot product a . b measures the length of the projection of b onto a,
       multiplied by the length of a.
     - The dot product can be used to measure displacement in a particular
       dirction.
     - The projection operation is closely related to the cosine function.The dot
       product a . b also is equal to |a| |b| cosθ, where theta is the angle between
       the vectors.
     
*** 2.8 Vector Cross Product [向量叉积]
    向量叉积不同于点积,点积生成一个 *标量*[scalar],而叉积生成一个3D向量同时 _不满足交换律_.
    叉积最重要的作用在于生成一个垂直于平面的向量,生成三角形或者多边形.
**** Geometric Interpretation [几何解释]
     向量的叉积生成一个同时与两个原向量正交[perpendicular]的新向量.
     向量叉积的模:
     $|a \times b| = |a| |b| sin\theta$
     a x b 产生的新向量可能指向两个相反的方向,判断方式如下:
     - 首先,把a的 *头*[head] 和b的 *尾*[tail]相连.
     - 其次,看a到b是顺时针还是逆时针.
     - 1) 如果在左手坐标系中:
       a到b是顺时针,则a x b 生成的新向量会靠近你.
       a到b是逆时针,则a x b 生成的新向量会远离你.
     - 2) 如果在右手坐标系中:
       a到b是顺时针,则a x b 生成的新向量会远离你.
       a到b是逆时针,则a x b 生成的新向量会靠近你.
*** 2.9 Norm of a Vector [范数]
    范数[norm][fn:norm],是具有长度概念的 *函数*.在线性代数等相关数学领域,其含义为 _为向量空间内的_
    _所有向量赋予非0的正常度或者大小._
    范数的本质是 *距离*,它把 _不能比较的向量通过函数来转换为可以比较的实数_.
    1-范数:
    $\vert x \vert_{p} \equiv (\sum_{i=1}^n |x_{i}|^p)^{1/p}$
    
    - $L^1$ norm.(p = 1). --> Taxicab norm (表示向量元素绝对值之和)

      $|x|_{1} \equiv \sum_{i=1}^n |x_{i}|$

    - $L^2$ norm.(p = 2). --> Euclidean norm (计算向量长度)
      
      $|x|_{2} \equiv \sqrt{\sum_{i=1}^n |x_{i^2}|}$

    - The infinity norm.(p = ∞) --> Chebyshev norm (求所有向量元素中最大值)

      $|x|_{∞} \equiv max(|x_{1},...,|x_{n}|)$
** Chapter 3 Multiple Coordinate Spaces[多坐标空间]
   关于多个坐标系统,我们会讨论如下问题:
   1. 为何需要多个坐标系?
   2. 对几个常见坐标系的介绍:
      - world space
      - object space
      - camera space
      - upright space
   3. 坐标系的 *转换*[transformation]
   4. 讨论 *嵌套坐标系*[nested coordinate spaces],主要用于 _3D对象的层级动画(animating 
   hierarchically segmented objects in 3D space)_

*** 3.1 Why bother with Multiple Coordinate Spaces?[为什么要使用多个坐标系?]
    从直觉上来说,我们把所有的东西放在一个坐标系里,记录每个东西的位置,是理所当然的做法.
    通常我们把这个坐标系叫做 *世界坐标系*[world coordinate space].
    但是考虑一个问题,当我们把一个物体置入世界坐标系的时候,到底怎么样才能清晰直观的表现
    它的位置,方向等信息?
    同样显而易见的是,我们以物体自身为坐标系,来表示它的 *位置*[position], *旋转*[rotation] 和
    *大小*[scale],符合我们的直觉的同时也更简单.
    而在这种情况下,最理想的办法无疑是让自身的坐标系和世界坐标系并存,让物体从自身坐标系转换
    到世界坐标系.
*** 3.2 Some Useful Coordinate Spaces
**** World Space
     世界坐标系是用来表示 *绝对位置*[absolute position] 的,在游戏中, 意味着它表示的是在游
     戏范围内最大的坐标空间.
     同样, *世界坐标系*[world coordinate space] 也被叫做 *全球*[global] 或者 *通用*[universal]
     坐标系.
**** Object Space
     *对象空间* 是指依附于某个具体对象的 *坐标空间*[cordinate space].
     同样的, *对象空间* 也被叫做 *model space* 或者是 *body space*.
     这里有个有趣的例子[fn:worldspace].
**** Camera Space
     首先要明白,Camera Space 是 1. _带有 *视点*[viewpoint]_ 2. _用于渲染的_ Object Space.
     在Camera Space中(Left-handed conventions),
     - +x --> *right*
     - +y --> *up*
     - +z --> *forward*
     需要区别的在于 *Camera Space* (是一个3D Space), *Screen Space*(是一个2D Space).
     为了让 Camera Space 映射到 Screen Space,我们需要用的一个技巧是 *投影*[projection].
**** Upright Space
     Upright Space 是什么意思?它表示的是 *World Space*  <---> *Object Space* 的 *中间状态*.
     就是说,
     - Upright Space 的轴分别 *平行*[parallel] 于 World Space 的轴.
     - Upright Space 的坐标原点与 *Object Space* 的坐标原点一致.

     为什么需要Upright Space?
     仔细想想,在世界坐标系中的物体的所有位置,都可以通过对该物体 *平移*[translation] 和
     *旋转*[rotation] 得到.
*** 3.3 Basis Vectors and Coordinate Space[基向量与坐标空间]
    在实际的游戏编程中,我们常常会遇到一个问题:我知道某个物体在当前坐标的具体位置,但是
    它在另一个坐标系中应该如何表示?
    这个过程被叫做 *coordinate space translation*[坐标空间转换].
**** Dual Perspectives[双重视角]
     我们已经知道,在世界坐标系中的物体的位置都可通过物体的平移与旋转得到.而在实际考虑
     问题的时候,我们的具体步骤是:
     1. 旋转
     2. 平移
     为什么要先旋转再平移?原因在于围绕 *原点* 进行旋转是 *线性变换*[linear transform],而围绕
     其他点旋转则是在进行 *仿射变换*[affine transformation],仿射变换要麻烦的多.
     如果我们要先平移再旋转,就需要进行如下步骤:
     1. 将旋转中心平移到原点
     2. 以原点为中心旋转到指定角度
     3. 平移
     而最终,为了能渲染出摄像机视野内的物体,我们需要将目标模型变换到 *Camera Space*.但是就算
     是转换到了 *Camera Space*,故事也还没有结束,我们还需要将顶点转换到 *Clip Space*,最后 *投影* 
     到 *Screen Space*.
     整个流程大概是:
     Object Space --> World Space --> Camera Space --> Clip Space --> Screen Space
     其中,World Space 到 Camera Space 则通过 *顶点着色器*[vertex shader] 完成.
     *active transformation*
     *passive transformation*
     active和passive都用来表示Object的状态,active表示移动Object,passive表示让Object静止,移动坐
     标系.
**** Specifying Coordinate Spaces[指定坐标空间]
     通过描述 *原点*[origin] 和 *轴*[axis],就能指定一个坐标空间.
     *原点* 是一个用来 _定义空间位置的点_,而 *轴* 则是用来 _描述空间方向的向量_.
     我们定义的原点是相对于 *父坐标空间*[parent coordinate space]而言的,因为在 *子空间*[child space]
     中,原点总被表示为(0,0,0).
**** Basis Vectors[基向量]
     $\vec{v} = x\vec{p}+y\vec{q}+z\vec{r}$
     其中,$\vec{p}=[1,0,0] \vec{q}=[0,1,0],\vec{r}=[0,0,1]$,也就是所谓的基向量.


     如何将本地坐标系中的位置转换到世界坐标系?
     1. 找到本地坐标系的原点,将 _原点以世界坐标系的位置_ 表示.
     2. 以upright坐标系的 *单位向量*[unit vector]为基础,分别将本地坐标系的单位向量(+x +y)在upright
     坐标系中表示.
     3. 
     原点位置
     + 根据向量在本地坐标系中的位置的标量值,分别乘以upright坐标系中表示的 _本地坐标系的单位向量_
     = 该本地向量在世界坐标系中的位置
     公式为:
     $\vec{w} = \vec{o} + b_{x}\vec{p} + b_{y}\vec{q}$
     以基向量的 *线性组合*[linear combination]的方式表示一个3D向量:
     $\vec{v} = x\vec{p} + y\vec{q} + z\vec{r}$
    
     在理想状况下,我们希望基向量都互相垂直并且具有相同的大小,然而现实往往并不能如愿.
     我们举以下几个例子来说明下非理想状况下的基向量的应用:

     1. _Scale an Object_
     当我们对一个物体进行缩放的时候,考虑到不是同时对x,y,z轴都进行缩放,所以往往缩放后的结果是原
     物体的基向量不再垂直或者具有相同的长度.

     2. _Texture Mapping/Bump Mapping_
     在 *表面*[surface]上建立一个轴(+z)平行于 *表面法线*[fn:surfacenormal]的本地坐标系通常会很有用.
     而另外的两个轴 u 和 v 分别被叫做 *切线* [tangent] 和 *次法线*[binormal],在2D纹理中,分别沿 *水平*
     和 *垂直* 方向延伸.
     通常在 *平面2D纹理*[flat 2D texture]中,通常会将纹理贴在不规则的表面上,并且基向量往往不能保证
     是互相垂直的.

     之所以基向量不必非要互相垂直,是因为在一个平面上,只要 _两个不平行的基向量_ 就能描述平面内的任意
     向量,也即是说,在同一平面内的任意两个不平行的基向量即可构成一个平面.
     这些由基向量线性变换得来的向量的集合被叫做 _the *span* of the basis_.由此可推:
     2 basis vectors --> the span is an infinite 2D plane.
     3 basis vectors --> the span is an infinite 3D plane.
     *linear span* --> 线性生成空间
     *rank* -->
     _秩,由基向量张成的空间的维度数量被叫做秩._
     the number of dimensions in the space _spanned by the basis_ is the *rank* of the basis.
     *linear dependent* --> 线性相关
     *linear independent* --> 线性无关 --> *满秩*[full rank]

     _如何判断一组向量是否线性相关?_
     $a_{1}\vec{v}_{1} + a_{2}\vec{v}_{2} +  ... a_{n}\vec{v}_{n} = 0$
     即:
     $\sum_{i=1}^n a_{i}\vec{v}_{i} = 0$
     若等式成立,则这组向量是线性相关的.

     A set of basis vectors that are _mutually perpendicular_ is called an *orthogonal basis*.
     一组互相垂直的基向量被叫做 *正交基*.
     *orthonormal basis*[标准正交基],在正交基的基础上还具有 *单位长度*[unit length].
*** 3.4 Nested Coordinate Spaces[嵌套坐标空间]
     *Articulated model*[关节模型] --> 由嵌套坐标空间构成的模型.
     在物体的动画系统中,使用嵌套坐标空间能简单高效的描述各个部分的运动关系.
*** 3.5 In Defense of Upright Space[再次为upright space站台]
     在程序代码里,一个数据类型如 *float3*,往往具有两个含义:
     1. 作为一个 *vector*
     2. 作为一个 *point*
     永远要记住,一个 *vector* 表示的是 _一段位移(同时具有大小和方向)_,而一个 *Point* 表示的是
     *位置*[Position].
** Chapter 4 Introduction to Matrices[矩阵导论]
   *矩阵*[Matrices],主要用来描述两个坐标空间之间的关系.它计算从一个坐标空间到另一个坐标
   空间的 _向量变换_ .
*** 4.1 Mathematical Definition of Matrix[矩阵的数学定义]
    A vector is an _array of scalars_,and a matrix is an _array of vectors_.
**** Matrix Dimensions and Notation[矩阵行列和符号]
     \begin{bmatrix}
              4 & 0 & 12\\
              -5 & \Sqrt{4} & 3\\
              12 & -4/3 & -1\\
              1/2 & 18 & 0 \\
     \end{bmatrix}
     这是一个 4(row)x3(col)矩阵.表示矩阵由4 *行*[row] 3 *列*[column]组成.
     \begin{bmatrix}
              m_{11} & m_{12} & m_{13}\\
              m_{21} & m_{22} & m_{23}\\
              m_{31} & m_{32} & m_{33}\\
     \end{bmatrix}
     符号 $m_{ij}$ 表示在M中i行j列的元素的值.需要注意的是在很多编程语言中,数组下标是从0开始的,而矩阵下
     标则是从1开始的.在编程的时候使用矩阵时,一定要注意区别.
**** Square Matrices[方阵]
     *方阵*[square matrices]就是 _行和列相等_ 的矩阵.
     *对角元素*[diagonal elements] 就是指 _行和列的下标相同_ 的 *方阵* 中的元素.
     如下:
     \begin{bmatrix}
              \boldsymbol{m_{11}} & m_{12} & m_{13}\\
              m_{21} & \boldsymbol{m_{22}} & m_{23}\\
              m_{31} & m_{32} & \boldsymbol{m_{33}}\\
     \end{bmatrix}

     *对角矩阵*[diagonal matrix] 就是指 *非对角元素* 为0的矩阵.
     如下:
     \begin{bmatrix}
              \boldsymbol{m_{11}} & 0 & 0\\
              0 & \boldsymbol{m_{22}} & 0\\
              0 & 0 & \boldsymbol{m_{33}}\\
     \end{bmatrix}
     *单位矩阵*[identity matrix] 就是指对角元素都为1的 *对角矩阵*.
     如下:
     \begin{equation}
     \boldsymbol{I_{3}} =
     \begin{bmatrix}
              \boldsymbol{1} & 0 & 0\\
              0 & \boldsymbol{1} & 0\\
              0 & 0 & \boldsymbol{1}\\
     \end{bmatrix}
     \end{equation}
     单位矩阵的特殊之处在于它是乘法恒等式.如果你让一个矩阵与单位矩阵做乘法,得到的是原矩阵.
     单位矩阵之于矩阵,就如同数字1之于标量.
**** Vectors as Matrices[向量作标量]
     矩阵通常由n行n列组成(n>=1),而一个 *向量*[vector]可以被看成是 *一行*[$1 \times n$] 或者是 *一列*[$n \times 1$]
     的矩阵.
     *行向量*[row vector] --> $1 \times n$ 矩阵
     e.g
     \begin{bmatrix}
     1 & 2 & 3
     \end{bmatrix}
     *列向量*[column vector] --> $n \times 1$ 矩阵
     e.g
     \begin{bmatrix}
     1 \\
     2 \\
     3
     \end{bmatrix}
**** Matrix Transposition[转置矩阵]
     假设有一个矩阵$\boldsymbol{M} (r \times c)$,则它的 *转置*[transpose] 矩阵为
     $\boldsymbol{M^T} (c \times r)$,有$\boldsymbol{M^T_{ij}} = \boldsymbol{M_{ji}}$.
     e.g
     \begin{equation}
     \begin{bmatrix}
              1 & 2 & 3\\
              4 & 5 & 6\\
              7 & 8 & 9\\
              10 & 11 & 12\\
     \end{bmatrix}
     ^T =
     \begin{bmatrix}
              1 & 4 & 7 & 10\\
              2 & 5 & 8 & 11\\
              3 & 6 & 9 & 12\\
     \end{bmatrix}
     \end{equation}

     \begin{equation}
     \begin{bmatrix}
              a & b & c\\
              d & e & f\\
              g & h & i\\
     \end{bmatrix}
     ^T =
     \begin{bmatrix}
              a & d & g\\
              b & e & h\\
              c & f & i\\
     \end{bmatrix}
     \end{equation}

     \begin{equation}
     \begin{bmatrix}
              x & y & z\\
     \end{bmatrix}
     ^T =
     \begin{bmatrix}
              x\\
              y\\
              z\\
     \end{bmatrix}
     \end{equation}
     如下,有两个结论:
     $(\boldsymbol{M}^T)^T = \boldsymbol{M}$
     $\boldsymbol{D^T} = \boldsymbol{D} , D = (Diagonal Matrix)$
**** Multiply a Matrix with Scalar[矩阵的标量乘法]
     与向量的标量乘法相同:
     \begin{equation}
     k \boldsymbol{M} = k
     \begin{bmatrix}
     m_{11} & m_{12} & m_{13} \\
     m_{21} & m_{22} & m_{23} \\
     m_{31} & m_{32} & m_{33} \\
     m_{41} & m_{42} & m_{43} \\
     \end{bmatrix} 
     =
     \begin{bmatrix}
     km_{11} & km_{12} & km_{13} \\
     km_{21} & km_{22} & km_{23} \\
     km_{31} & km_{32} & km_{33} \\
     km_{41} & km_{42} & km_{43} \\
     \end{bmatrix} 
     \end{equation}
**** Multiplying Two Matrix[矩阵乘法]
     $\boldsymbol{A} (r \times n) , \boldsymbol{B} (n \times c) , \boldsymbol{AB} (n \times c)$
     矩阵乘法中,第一个矩阵的列数必须与第二个矩阵的行数相等才能进行.
     同时,矩阵乘法不满足交换律.
     公式如下:
     $c_{ij} = \sum_{k=1}^n a_{ik}b_{kj}$
     第一个矩阵的行向量与第二个矩阵的列向量做 *点乘*.
     e.g
     \begin{equation}
     \boldsymbol{AB} =
     \begin{bmatrix}
     a_{11} & a_{12} \\
     a_{21} & a_{22}
     \end{bmatrix}
     \begin{bmatrix}
     b_{11} & b_{12} \\
     b_{21} & b_{22}
     \end{bmatrix}
     =
     \begin{bmatrix}
     a_{11}b_{11} + a_{12}b_{21} & a_{11}b_{12} + a_{12}b_{22} \\
     a_{21}b_{11} + a_{22}b_{21} & a_{21}b_{12} + a_{22}b_{22} \\
     \end{bmatrix}
     \end{equation}

     \begin{equation*}
     \begin{flushleft}
     \boldsymbol{A} =
     \begin{bmatrix}
     -3 & 0 \\
     5 & 1/2
     \end{bmatrix},
     \boldsymbol{B} =
     \begin{bmatrix}
     -7 & 2 \\
     4 & 6 
     \end{bmatrix},
     \\
     \boldsymbol{AB} =
     \begin{bmatrix}
     (-3)(-7) + (0)(4) & (-3)(2) + (0)(6) \\
     (5)(-7) + (1/2)(4) & (5)(2) + (1/2)(6)\\
     \end{bmatrix}
     =
     \begin{bmatrix}
     21 & -6 \\
     -33 & 13 
     \end{bmatrix}
     \end{flushleft}
     \end{equation*}
     下面是矩阵乘法的一些特点:
     - M与方阵相乘,得到的矩阵大小和原矩阵相同.而M与单位矩阵相乘,结果是M自身.
       $\boldsymbol{MI} = \boldsymbol{IM} = \boldsymbol{M}$

     - 矩阵乘法不满足交换律
       $\boldsymbol{AB} \neq  \boldsymbol{BA}$

     - 矩阵乘法满足结合律
       $\boldsymbol{(AB)C} = \boldsymbol{A(BC)}$

     - 标量(或向量)与矩阵相乘满足结合律
       $\boldsymbol{(kA)B} = \boldsymbol{k(AB)}$
       $\boldsymbol{(\vec{v}A)B} = \boldsymbol{\vec{v}(AB)}$

     - 矩阵乘法的转置
       $\boldsymbol{(AB)^T} = \boldsymbol{B^TA^T}$
**** Multiplying a Vector and a Matrix[矩阵与向量相乘]
     首先要注意的是,向量与矩阵相乘或者矩阵与向量相乘的前提是,第一个参数的 *列* 必须要与第二个参数
     的 *行* 一致,否则不能进行乘法运算.
     \begin{equation*}
     \begin{flushleft}
     \begin{bmatrix}
     x & y & z
     \end{bmatrix}
     \begin{bmatrix}
     m_{11} & m_{12} & m_{13} \\
     m_{21} & m_{22} & m_{23} \\
     m_{31} & m_{32} & m_{33} \\
     \end{bmatrix}
     =
     \\
     \begin{bmatrix}
     xm_{11}+ym_{21}+zm_{31} & xm_{12}+ym_{22}+zm{32} & xm_{13}+ym_{23}+zm_{33}
     \end{bmatrix}
     \end{flushleft}
     \end{equation*}

     \begin{equation*}
     \begin{flushleft}
     \begin{bmatrix}
     m_{11} & m_{12} & m_{13} \\
     m_{21} & m_{22} & m_{23} \\
     m_{31} & m_{32} & m_{33} \\
     \end{bmatrix}
     \begin{bmatrix}
     x \\
     y \\ z
     \end{bmatrix}
     =
     \\
     \begin{bmatrix}
     xm_{11}+ym_{12}+zm_{13} & xm_{21}+ym_{22}+zm{23} & xm_{31}+ym_{32}+zm_{33}
     \end{bmatrix}
     \end{flushleft}
     \end{equation*}

     向量与矩阵相乘满足分配律:
     e.g
     $(\vec{v}+\vec{w})\boldsymbol{M} = \vec{v}\boldsymbol{M} + \vec{w}\boldsymbol{M}$
     Finally, and perhaps most important at all,the result of the multiplication is a _linear combination_
     _of the rows or columns of the matrix_.
**** Row versus Column Vectors[行向量和列向量]
     \begin{equation*}
     \begin{flushleft}
     \begin{bmatrix}
     x & y & z
     \end{bmatrix}
     \begin{bmatrix}
     m_{11} & m_{12} & m_{13} \\
     m_{21} & m_{22} & m_{23} \\
     m_{31} & m_{32} & m_{33} \\
     \end{bmatrix}
     =
     \\
     \begin{bmatrix}
     xm_{11}+ym_{21}+zm_{31} & xm_{12}+ym_{22}+zm{32} & xm_{13}+ym_{23}+zm_{33}
     \end{bmatrix}
     \end{flushleft}
     \end{equation*}

     \begin{equation*}
     \begin{flushleft}
     \begin{bmatrix}
     m_{11} & m_{12} & m_{13} \\
     m_{21} & m_{22} & m_{23} \\
     m_{31} & m_{32} & m_{33} \\
     \end{bmatrix}
     \begin{bmatrix}
     x \\
     y \\ z
     \end{bmatrix}
     =
     \\
     \begin{bmatrix}
     xm_{11}+ym_{12}+zm_{13} & xm_{21}+ym_{22}+zm{23} & xm_{31}+ym_{32}+zm_{33}
     \end{bmatrix}
     \end{flushleft}
     \end{equation*}

     从上面的矩阵与相同元素的行/列向量相乘我们可以发现,相乘的结果是不同的.
     先解释一下为什么会有这种区别,再给出建议使用 *行向量*[row vector]给出一些理由.
     - *行向量* 是 _从左到右_ 的顺序读写的.特别是在进行多个变换的时候. 
       *列向量* 却必须 _从右到左_.
       e.g
       $\vec{v} \boldsymbol{ABC}$ (row vector)
       $\boldsymbol{CBA} \vec{v}$ (col vector)

     - 尽管在实际生活中,使用列向量会让矩阵看起来更直观(特别是在维数增加的时候),但是在游戏编程里,
     代码的可读性往往比公式的可读性更重要.

     在许多API里,DirectX使用的是行向量,而OpenGL使用的则是列向量,在实际编程中要注意区分.
*** 4.2 Geometric Interpretation of Matrix[矩阵的几何解释]
    不管怎么样,一个 *方阵*[square matrix] 可以描述 _任何矩阵变换_.
    一个 *线性变换* 可以 *伸展*[stretch] 坐标空间,但是却不能 *弯曲*[warp] 它.
    常见的线性变换包括:
    - *rotation*[旋转]
    - *scale*[缩放]
    - *orthographic projection*[正交投影]
    - *shearing*[裁剪]
    - *reflection*[反射]

    已知 *基向量*[basis vectors] $\vec{i} = [1,0,0],\vec{j} = [0,1,0], \vec{k} = [0,0,1]$,与任意矩阵$\boldsymbol{M}$
    相乘结果如下:
    \begin{equation*}
    \boldsymbol{\vec{i}M} =
    \begin{bmatrix}
    1 & 0 & 0
    \end{bmatrix}
    \begin{bmatrix}
    m_{11} & m_{12} & m_{13} \\
    m_{21} & m_{22} & m_{23} \\
    m_{31} & m_{32} & m_{33} \\
    \end{bmatrix}
    =
    \begin{bmatrix}
    m_{11} & m_{12} & m_{13}
    \end{bmatrix}
    \end{equation*}

    \begin{equation*}
   \boldsymbol{\vec{i}M} =
   \begin{bmatrix}
   0 & 1 & 0
   \end{bmatrix}
   \begin{bmatrix}
   m_{11} & m_{12} & m_{13} \\
   m_{21} & m_{22} & m_{23} \\
   m_{31} & m_{32} & m_{33} \\
   \end{bmatrix}
   =
   \begin{bmatrix}
   m_{21} & m_{22} & m_{23}
   \end{bmatrix}
   \end{equation*}

    \begin{equation*}
   \boldsymbol{\vec{i}M} =
   \begin{bmatrix}
   0 & 0 & 1
   \end{bmatrix}
   \begin{bmatrix}
   m_{11} & m_{12} & m_{13} \\
   m_{21} & m_{22} & m_{23} \\
   m_{31} & m_{32} & m_{33} \\
   \end{bmatrix}
   =
   \begin{bmatrix}
   m_{31} & m_{32} & m_{33}
   \end{bmatrix}
   \end{equation*}

    而我们之前已经知道任何向量都可以表示成基向量的 *线性组合*[linear combination],
    $\boldsymbol{\vec{v}} = v_{x} \boldsymbol{\vec{i}} + v_{y} \boldsymbol{\vec{j}} + v_{z} \boldsymbol{\vec{k}}$
    则向量与矩阵相乘可表示为:
    \begin{equation*}
    \begin{flushleft}
    \boldsymbol{\vec{v}M} = 
    (v_{x} \boldsymbol{\vec{i}} + v_{y} \boldsymbol{\vec{j}} + v_{z} \boldsymbol{\vec{k}}) \boldsymbol{M}
    \\=
    (v_{x} \boldsymbol{\vec{i}})\boldsymbol{M} + 
    (v_{y} \boldsymbol{\vec{j}})\boldsymbol{M} + 
    (v_{z} \boldsymbol{\vec{k}})\boldsymbol{M})
    \\=
    v_{x} (\boldsymbol{\vec{i}} \boldsymbol{M}) + 
    v_{y} (\boldsymbol{\vec{j}} \boldsymbol{M}) + 
    v_{z} (\boldsymbol{\vec{k}} \boldsymbol{M}))
    \\=
    v_{x}
    \begin{bmatrix}
    m_{11} & m_{12} & m_{13}
    \end{bmatrix}
    +v_{y}
    \begin{bmatrix}
    m_{21} & m_{22} & m_{23}
    \end{bmatrix}
    +v_{z}
    \begin{bmatrix}
    m_{31} & m_{32} & m_{33}
    \end{bmatrix}
    \end{flushleft}
    \end{equation*}
    等价于:
    \begin{equation*}
    \begin{flushleft}
    \boldsymbol{\vec{v}M} = 
    \begin{bmatrix}
    v_{x} & v_{y} & v_{z}
    \end{bmatrix}
    \begin{bmatrix}
    \boldsymbol{-p-}\\
    \boldsymbol{-q-}\\
    \boldsymbol{-r-}\\
    \end{bmatrix}
    =
    v_{x} \boldsymbol{\vec{p}} + v_{y} \boldsymbol{\vec{q}} + v_{z} \boldsymbol{\vec{r}}
    \end{flushleft}
    \end{equation*}

    从上可知,矩阵的行其实可以看成是 _该坐标空间的基向量[basis vectors]_.
    e.g
    \begin{equation*}
    \boldsymbol{M}=
    \begin{bmatrix}
    2 & 3 \\
    1 & 2
    \end{bmatrix}
    \end{equation*}
    在这里,可以看成是,基向量$\boldsymbol{p} = [2 , 3], \boldsymbol{q} = [1 , 2]$.
    把n维矩阵看成是n个基向量的集合,那么向量与矩阵的乘法,就可以看成是 _对每个矩阵中的基向量做线性_
    _组合_
    *总结*

    - The rows of a *square matrix* can be interpreted as the basis vectors of a coordinate space.
      方阵的行可以看成是坐标空间中的基向量.

    - To transform a vector from original coordinate space to the new coordinate space,we multiply
      the vector by matrix.
      向量与矩阵相乘的几何意义是:把向量从原坐标空间转换到新的坐标空间.

    - The transformation from the original coordinate space to the coordinate space defined by these
    basis vectors is a linear transformation. A linear transformation preserves straight lines,and parallel
    lines remain parallel. However, angles, lengths, areas, and volumes may be altered after transfor-
    mation.
    由基向量定义的从原始坐标空间到新的坐标空间的转换是一个线性变换.线性变换的时候直线和平行线仍
    然保持平行.但是,角度,长度,面积,体积等都会受变换影响改变.

    - Multiplying the zero vector by any square matrix results in the zero vector.Therefor, the linear trans-
    formation represented by a square matrix has the same origin as the original coordinate space -->
    the transformation does not contain translation.
    方阵与零向量相乘只会得到一个零向量.对方阵做线性变换不会改变原点坐标--> _变换不包括平移_.

    - We can visualize a matrix by visualizing the basis vector of the coordinate space after transfor-
    mation.These basis vectors form an 'L' in 2D,and a tripod in 3D.Using a box or auxiliary object also
    helps in visualiation.
    通过把矩阵的行当作基向量,我们可以把矩阵形象化.在2D中,基向量呈L型,在3D中就像一个三脚架.
*** 4.3 The Bigger Picture of Linear Algebra[关于更多:线性代数]
    线性代数是用来操作和求解线性方程的.在游戏中,求解线性方程组最频繁的是 *物理引擎*[physics 
    engine].另外一些常见的应用是 *最小二乘方法*[least squares approximation] 和 *数据拟合*[data fitting].
    虽然传统的线性代数和方程组在基础的游戏编程中不是必须的,但是在很多高级领域,它们确是必不可少的,
    来看下现在的某些技术:
    *fluid*[流体], *cloth*[布料], *hair simulation(and rendering)*[头发模拟(和渲染)],
    *procedural animation of characters*[角色程序动画], *real-time global illumination*[实施全局光照],
    *machine vision*[机器视觉], *gesture recognition*[手势识别] ...
    都需要用到线性代数.
** Chapter 5 Matrices and Linear Transformations[矩阵和线性变换]
   *仿射变换*[affline transformation] = *线性变换*[linear transformation] + *平移*[displacement]
*** 5.1 Rotation[旋转]
**** Rotation in 2D[2D下的旋转]
     在2D坐标中,只有一种可能的旋转 -- 围绕 *点*[point]旋转.
     2D下的旋转公式如下:
     \begin{equation*}
     \boldsymbol{R}(\theta) =
     \begin{bmatrix}
     -\boldsymbol{p'}- \\
     -\boldsymbol{q'}- \\
     \end{bmatrix}
     =
      \begin{bmatrix}
      cos\theta & sin\theta \\
      -sin\theta & cos\theta
     \end{bmatrix}
     \end{equation*}
**** 3D Rotation about Cardinal Axes[围绕坐标轴的3D旋转]
     在3D场景下,围绕 *轴*[axis] 的旋转比围绕点的旋转更为普遍.
     3D场景下绕坐标轴旋转的公式如下:
     围绕x轴旋转:
     \begin{equation*}
     \boldsymbol{R}_{x}(\theta) =
     \begin{bmatrix}
     -\boldsymbol{p'}- \\
     -\boldsymbol{q'}- \\
     -\boldsymbol{r'}- \\
     \end{bmatrix}
     =
     \begin{bmatrix}
     1 & 0 & 0 \\
     0 & cos\theta &sin\theta \\
     0 & -sin\theta & cos\theta
     \end{bmatrix}
     \end{equation*}
     围绕y轴旋转:
     \begin{equation*}
     \boldsymbol{R}_{y}(\theta) =
     \begin{bmatrix}
     -\boldsymbol{p'}- \\
     -\boldsymbol{q'}- \\
     -\boldsymbol{r'}- \\
     \end{bmatrix}
     =
     \begin{bmatrix}
     cos\theta & 0 & -sin\theta \\
     0 & 1 & 0 \\
     sin\theta & 0 & cos\theta & \\
     \end{bmatrix}
     \end{equation*}
     围绕z轴旋转:
     \begin{equation*}
     \boldsymbol{R}_{z}(\theta) =
     \begin{bmatrix}
     -\boldsymbol{p'}- \\
     -\boldsymbol{q'}- \\
     -\boldsymbol{r'}- \\
     \end{bmatrix}
     =
     \begin{bmatrix}
     cos\theta & sin\theta & 0\\
     -sin\theta & cos\theta & 0 \\
     0 & 0 & 1\\
     \end{bmatrix}
     \end{equation*}
**** 3D Rotation about an Arbitrary Axis[围绕任意轴的3D旋转]
     在不考虑位移的情况下,现在我们讨论如何围绕任意轴做旋转.
     首先,定义围绕任意轴旋转的角度为$\theta$,而该轴则由单位向量 $\hat{n}$ 来定义.
     $\boldsymbol{v'} = \boldsymbol{vR}(\hat{n},\theta)$
     其中,$\boldsymbol{v'}$ 表示围绕单位向量$\hat{n}$ 旋转角度$\theta$ 后的值.
     在实现矩阵之前,我们先来看看能不能把$v'$ 用$\vec{v}$,$\hat{n}$ 和 $\theta$ 描述出来.
     1. 首先,一个向量总是可以看成是多段基向量相加组成,
        $\vec{v} = x\hat{p} + y\hat{q} + z\hat{r}$
     2. 同样,一个向量可以表示成
        $\vec{v} = \vec{v}_{||} + \vec{v}_{\perp}$,其中$\vec{v}_{||}$ 可以表示为向量在某一向量上的投影
     3. 由此,有
        $\vec{v} = \vec{v}_{||} + \vec{v}_{\perp} = proj(\vec{v},\hat{n}) + \vec{v}_{\perp}$
        $\vec{v'}= \vec{v'}_{||} + \vec{v'}_{\perp} = proj(\vec{v'},\hat{n'}) + \vec{v'}_{\perp}$
     4. 其中有 $\vec{v}_{||} = \vec{v'}_{||}$ ,所以问题被化简为求向量 $\vec{v'}_{\perp}$ .
     5. $\vec{v}_{\perp}$ 绕轴旋转$\theta$ 得到 $\vec{v'}_{\perp}$,根据此条件来求出$\vec{v'}_{\perp}$ .
     6. $\hat{n}$ 和 $\vec{v}_{\perp}$ 的叉积可以得到一个分别垂直于它们的向量 $\vec{w}$ ,而显而易见的是,
        $\vec{v}_{\perp}$ , $\vec{v'}_{\perp}$  和 $\vec{w}$ 同处一个平面内,同时 $\vec{v}_{\perp}$ (作x轴) 和 $\vec{w}$ (作y轴)还构成了一个正交的2D坐标空间.
        由此,我们就可以在正交的2D坐标空间内通过坐标轴旋转来得到向量 $\vec{v'}_{\perp}$.可得出
        $\vec{v'}_{\perp} = cos\theta \vec{v}_{\perp} + sin\theta \vec{w}$

     综上,各向量可表示为:
     $\vec{v}_{||} = (\vec{v} \cdot \hat{n})\hat{n}$
     $\vec{v}_{\perp} = \vec{v} - \vec{v}_{||} = \vec{v} - (\vec{v} \cdot \hat{n})\hat{n}$
     $\vec{w} = \hat{n} \times \vec{v}_{\prep} = \hat{n} \times (\vec{v} - \vec{v}_{||}) = \hat{n} \times \vec{v} - 0 = \hat{n} \times \vec{v}$
     $\vec{v'}_{\perp} = cos\theta\vec{v}_{\perp} + sin\theta\vec{w} = cos\theta(\vec{v}-(\vec{v} \cdot \hat{n})\hat{n}) + sin\theta(\hat{n} \times \vec{v}))$
     $\vec{v'} = \vec{v'}_{\perp} + \vec{v'}_{||} = cos\theta(\vec{v}-(\vec{v} \cdot \hat{n})\hat{n}) + sin\theta(\hat{n} \times \vec{v}) + (\vec{v} \cdot \hat{n})\hat{n}$
     
     \begin{equation*}
     p =
     \begin{bmatrix}
     1 & 0 & 0 \\
     \end{bmatrix},
     p' =
     \begin{bmatrix}
     n_{x^2}(1-cos\theta) + cos\theta \\
     n_{x}n_{y}(1-cos\theta) + n_{z}sin\theta \\
     n_{x}n_{z}(1-cos\theta) - n_{y}sin\theta
     \end{bmatrix}^T
     \end{equation*}

     \begin{equation*}
     q =
     \begin{bmatrix}
     0 & 1 & 0 \\
     \end{bmatrix},
     q' =
     \begin{bmatrix}
     n_{x}n_{y}(1-cos\theta) - n_{z}sin\theta \\
     n_{y^2}(1-cos\theta) + cos\theta \\
     n_{y}n_{z}(1-cos\theta) + n_{x}sin\theta
     \end{bmatrix}^T
     \end{equation*}

     \begin{equation*}
     r =
     \begin{bmatrix}
     0 & 0 & 1 \\
     \end{bmatrix},
     r' =
     \begin{bmatrix}
     n_{x}n_{z}(1-cos\theta) + n_{y}sin\theta \\
     n_{y}n_{z}(1-cos\theta) - n_{x}sin\theta \\
     n_{z^2}(1-cos\theta) + cos\theta \\
     \end{bmatrix}^T
     \end{equation*}

     \begin{equation*}
     \boldsymbol{R(\hat{n},\theta)} =
     \begin{bmatrix}
     -p'- \\
     -q'- \\
     -r'- \\
     \end{bmatrix} =
     \begin{bmatrix}
     n_{x^2}(1-cos\theta) + cos\theta & n_{x}n_{y}(1-cos\theta) + n_{z}sin\theta & n_{x}n_{z}(1-cos\theta) - n_{y}sin\theta \\
     n_{x}n_{y}(1-cos\theta) - n_{z}sin\theta & n_{y^2}(1-cos\theta) + cos\theta & n_{y}n_{z}(1-cos\theta) + n_{x}sin\theta \\
     n_{x}n_{z}(1-cos\theta) + n_{y}sin\theta & n_{y}n_{z}(1-cos\theta) - n_{x}sin\theta & n_{z^2}(1-cos\theta) + cos\theta
     \end{bmatrix}
     \end{equation*}
*** 5.2 Scale[缩放]
    在缩放的时候,我们往往会考虑两种缩放的情况.
    一种是 *Uniform Scale*,即表示对整个物体以原点为中心,全体等比例缩放.
    如果缩放比例为k的话,则缩放长度为k,缩放面积为k^2,缩放体积为k^3.

    一种是 *None-uniform Scale*,即表示可以让物体沿各个方向缩放.
    由于缩放的大小取决于缩放方向,所以k的大小会造成不同的影响:
    $|k| <1$ -> 物体在该方向上会变得更短,$|k| > 1$ -> 物体在该方向上会变得更长.
    $k = 0$ -> 物体 *投影*[projection] 在该方向上, $k < 0$  -> 造成物体的 *反射*[reflection].
**** Scaling along the Cardinal Axes[以坐标轴缩放]
     先考虑2D的情况,其实在2D的情况下很简单,我们只需要将基向量乘以k就行了.
     \begin{equation*}
     \boldsymbol{p'} = k_{x} \boldsymbol{p} = k_{x}
     \begin{bmatrix}
     1 & 0 \\
     \end{bmatrix}
     =
     \begin{bmatrix}
     k_{x} & 0 \\
     \end{bmatrix}
     ,
     \boldsymbol{q'} = k_{y} \boldsymbol{q} = k_{y}
     \begin{bmatrix}
     0 & 1 \\
     \end{bmatrix}
     =
     \begin{bmatrix}
     0 & k_{y} \\
     \end{bmatrix}.
     \end{equation*}
     由此可得Matrix $S(k_{x},k_{y})$ :

     \begin{equation*}
     \boldsymbol{S}(k_{x},k_{y}) =
     \begin{bmatrix}
     \boldsymbol{-p'-} \\
     \boldsymbol{-q'-}
     \end{bmatrix} =
     \begin{bmatrix}
     k_{x} & 0\\
     0 & k_{y}
     \end{bmatrix}
     \end{equation*}

     在3D中,表达也很简单,由2D可推:

     \begin{equation*}
     \boldsymbol{S}(k_{x},k_{y},k_{z}) =
     \begin{bmatrix}
     \boldsymbol{-p'-} \\
     \boldsymbol{-q'-} \\
     \boldsymbol{-r'-}
     \end{bmatrix} =
     \begin{bmatrix}
     k_{x} & 0 & 0\\
     0 & k_{y} & 0 \\
     0 & 0 & k_{z} 
     \end{bmatrix}
     \end{equation*}

     如果要让矩阵与任意的向量相乘,结果就是把向量的每个部分分别扩大,结果如下

     \begin{equation*}
     \begin{bmatrix}
     x & y & z \\
     \end{bmatrix}
     \begin{bmatrix}
     k_{x} & 0 & 0\\
     0 & k_{y} & 0 \\
     0 & 0 & k_{z} 
     \end{bmatrix} =
     \begin{bmatrix}
     k_{x}x & k_{y}y & k_{z}z \\
     \end{bmatrix}
     \end{equation*}
**** Scaling in an Arbitrary Direction[以任意方向缩放]
     对比按照任意轴进行旋转,按照任意方向缩放与它有共通之处.在此我们考虑,绕任意方向旋转,就是绕 _与_
     _该方向平行的 *基向量* 按一定 *长短* 缩放_,那么,这里就产生了两个参数: *基向量* 和 *长短*.
     在此,我们将问题表示为: $\boldsymbol{S}(\hat{n},k)$
     由此,参考绕任意轴旋转,我们可以得出以下方程:
     $\vec{v} = \vec{v}_{||} + \vec{v}_{\perp}$,
     $\vec{v}_{||} = (\vec{v} \cdot \hat{n}) \hat{n}$,
     $\vec{v'}_{\perp} = \vec{v}_{\perp} = \vec{v} - \vec{v}_{||} = \vec{v} - (\vec{v} \cdot \hat{n}) \hat{n}$,
     $\vec{v'}_{||} = k\vec{v}_{||} = k(\vec{v} \cdot \hat{n}) \hat{n}$,
     $\vec{v'} = \vec{v'}_{||} + \vec{v'}_{\perp} = k(\vec{v} \cdot \hat{n}) \hat{n} + \vec{v} - (\vec{v} \cdot \hat{n}) \hat{n} = \vec{v} + (k-1)(\vec{v}\cdot \hat{n}) \hat{n}$.
     由此,在基向量为$\vec{p}(1,0),\vec{q}(0,1)$ 的2D空间中, 可得:
     \begin{align*}
     \vec{p'} = \vec{p} + (k-1) (\vec{p}\cdot \hat{n}) \hat{n} =
     \begin{bmatrix}
     1 \\
     0 \\
     \end{bmatrix}
     + 
     (k-1) (
     \begin{bmatrix}
     1 \\
     0 \\
     \end{bmatrix}
     \cdot 
     \begin{bmatrix}
     n_{x} \\
     n_{y} \\
     \end{bmatrix}
     ) 
     \begin{bmatrix}
     n_{x} \\
     n_{y} \\
     \end{bmatrix}
     \\=
     \begin{bmatrix}
     1 \\
     0 \\
     \end{bmatrix}
     + (k-1) 
     n_{x}
     \begin{bmatrix}
     n_{x} \\
     n_{y} \\
     \end{bmatrix}
     \\=
     \begin{bmatrix}
     1 \\
     0 \\
     \end{bmatrix}
     +
     \begin{bmatrix}
     (k-1)n_{x^2} \\
     (k-1)n_{x}n_{y} \\
     \end{bmatrix}
     \\=
     \begin{bmatrix}
     1+(k-1)n_{x^2} \\
     (k-1)n_{x}n_{y} \\
     \end{bmatrix}
     \end{align*}

     同理可得,
     \begin{equation*}
     \vec{q} = 
     \begin{bmatrix}
     0 & 1 \\
     \end{bmatrix},
     \vec{q'} = 
     \begin{bmatrix}
     (k-1)n_{x}n_{y} \\
     1+(k-1)n_{y}^2
     \end{bmatrix}
     \end{equation*}
     现在我们知道在2D空间中如何表示任意方向上k的缩放了:
     \begin{equation*}
     \boldsymbol{S}(\hat{n},k) = 
     \begin{bmatrix}
     -\boldsymbol{p'}- \\
     -\boldsymbol{q'}-
     \end{bmatrix} =
     \begin{bmatrix}
     1+(k-1)n_{x^2} & (k-1)n_{x}n_{y}\\
     (k-1)n_{x}n_{y} & 1+(k-1)n_{y^2}
     \end{bmatrix}
     \end{equation*}
     同理,在3D空间中则有:
     \begin{equation*}
     \boldsymbol{S}(\hat{n},k) = 
     \begin{bmatrix}
     -\boldsymbol{p'}- \\
     -\boldsymbol{q'}- \\
     -\boldsymbol{r'}-
     \end{bmatrix} =
     \begin{bmatrix}
     1+(k-1)n_{x^2} & (k-1)n_{x}n_{y} & (k-1)n_{x}n_{z}\\
     (k-1)n_{x}n_{y} & 1+(k-1)n_{y^2} & (k-1)n_{y}n_{z}\\
     (k-1)n_{x}n_{z} & (k-1)n_{y}n_{z} & 1+(k-1)n_{z^2}\\
     \end{bmatrix}
     \end{equation*}
*** 5.3 Orthographic Projection[正交投影]
    简而言之,所谓的 *投影*[projection] 就是一种 *降维操作*.从上一节缩放的知识我们可以推断,在某一个
    方向上将缩放的k值取0,就完成了投影的操作(在2D中被转换为平行的直线,在3D中被转换为一个平面).这种
    投影方式被称作 *正交投影*[orthographic projection],在后面还会学习另一种投影, *透视投影*[perspective
    projection].
***** Projecting onto a Cardinal Axis or Plane[投影到坐标轴或者平面上]
      最简单的投影就是投影在 *坐标轴*[cardinal axis](2D) 和 *平面*[plane](3D).
      投影到坐标轴:
      \begin{equation*}
      \boldsymbol{P_{x}} = \boldsymbol{S}(
      \begin{bmatrix}
      0 & 1 \\
      \end{bmatrix}
      ,0) =
      \begin{bmatrix}
      1 & 0 \\
      0 & 0 \\
      \end{bmatrix}
      \end{equation*}

      \begin{equation*}
      \boldsymbol{P_{x}} = \boldsymbol{S}(
      \begin{bmatrix}
      1 & 0 \\
      \end{bmatrix}
      ,0) =
      \begin{bmatrix}
      0 & 0 \\
      0 & 1 \\
      \end{bmatrix}
      \end{equation*}

      投影到平面:

      \begin{equation*}
      \boldsymbol{P_{xy}} = \boldsymbol{S}(
      \begin{bmatrix}
      0 & 0 & 1\\
      \end{bmatrix}
      ,0) =
      \begin{bmatrix}
      1 & 0 & 0\\
      0 & 1  & 0\\
      0 & 0 & 0\\
      \end{bmatrix}
      \end{equation*}

      \begin{equation*}
      \boldsymbol{P_{xz}} = \boldsymbol{S}(
      \begin{bmatrix}
      0 & 1 & 0\\
      \end{bmatrix}
      ,0) =
      \begin{bmatrix}
      1 & 0 & 0\\
      0 & 0  & 0\\
      0 & 0 & 1\\
      \end{bmatrix}
      \end{equation*}

      \begin{equation*}
      \boldsymbol{P_{yz}} = \boldsymbol{S}(
      \begin{bmatrix}
      1 & 0 & 0\\
      \end{bmatrix}
      ,0) =
      \begin{bmatrix}
      0 & 0 & 0\\
      0 & 1  & 0\\
      0 & 0 & 1\\
      \end{bmatrix}
      \end{equation*}
***** Projecting onto an Arbitrary Line or Plane[投影到任意直线或平面]
      参考上一节的内容,只需要将$\hat{n},和k$ 代入即可.
      2D时,
      \begin{equation*}
      \boldsymbol{S}(\hat{n},0) = 
      \begin{bmatrix}
      1+(0-1)n_{x^2} & (0-1)n_{x}n_{y}\\
      (0-1)n_{x}n_{y} & 1+(0-1)n_{y^2}
      \end{bmatrix}=
      \begin{bmatrix}
      1-n_{x^2} & -n_{x}n_{y}\\
      -n_{x}n_{y} & 1-n_{y^2}
      \end{bmatrix}
      \end{equation*}

      3D时,
      \begin{equation*}
      \boldsymbol{S}(\hat{n},k) = 
      \begin{bmatrix}
      1+(0-1)n_{x^2} & (0-1)n_{x}n_{y} & (0-1)n_{x}n_{z}\\
      (0-1)n_{x}n_{y} & 1+(0-1)n_{y^2} & (0-1)n_{y}n_{z}\\
      (0-1)n_{x}n_{z} & (0-1)n_{y}n_{z} & 1+(0-1)n_{z^2}\\
      \end{bmatrix}=
      \begin{bmatrix}
      1-n_{x^2} & -n_{x}n_{y} & -n_{x}n_{z}\\
      -n_{x}n_{y} & 1-n_{y^2} & -n_{y}n_{z}\\
      -n_{x}n_{z} & -n_{y}n_{z} & 1-n_{z^2}\\
      \end{bmatrix}
      \end{equation*}
*** 5.4 Reflection[反射]
    *反射*[reflection],又叫 *镜像*[mirroring], 对象以某条线(2D)或者某个平面(3D)创造一个它的镜像.要完
    成镜像的操作也很简单,参考上一节,我们将 $k$ 的值代换为1就能得到物体的镜像了.
    2D的情况下:
    \begin{equation*}
   \boldsymbol{R}(\hat{n}) = 
   \boldsymbol{S}(\hat{n},-1) = 
   \begin{bmatrix}
   1+(-1-1)n_{x^2} & (-1-1)n_{x}n_{y}\\
   (-1-1)n_{x}n_{y} & 1+(-1-1)n_{y^2}
   \end{bmatrix}=
   \begin{bmatrix}
   1-2n_{x^2} & -2n_{x}n_{y}\\
   -2n_{x}n_{y} & 1-2n_{y^2}
   \end{bmatrix}
   \end{equation*}
    3D的情况下:
    \begin{equation*}
    \boldsymbol{R}(\hat{n}) = 
    \boldsymbol{S}(\hat{n},-1) = 
    \begin{bmatrix}
    1+(-1-1)n_{x^2} & (-1-1)n_{x}n_{y} & (-1-1)n_{x}n_{z}\\
    (-1-1)n_{x}n_{y} & 1+(-1-1)n_{y^2} & (-1-1)n_{y}n_{z}\\
    (-1-1)n_{x}n_{z} & (-1-1)n_{y}n_{z} & 1+(-1-1)n_{z^2}\\
    \end{bmatrix}=
    \begin{bmatrix}
    1-2n_{x^2} & -2n_{x}n_{y} & -2n_{x}n_{z}\\
    -2n_{x}n_{y} & 1-2n_{y^2} & -2n_{y}n_{z}\\
    -2n_{x}n_{z} & -2n_{y}n_{z} & 1-2n_{z^2}\\
    \end{bmatrix}
    \end{equation*}
*** 5.5 Shearing[裁剪]
    *裁剪*[shearing]看起来像是在歪斜坐标空间.与缩放不同的是,裁剪 _不会改变_ 物体的 *面积*[area]和
    *体积*[volume],相同的在于两者都会改变物体的角度大小.
    裁剪变换并不经常被使用,它也被称作 *斜变换*[skew transformation].要注意的是,在同时混合了 *裁剪* 
    和 *缩放* 的变换中,由于两者变换的时候一个不成比例(裁剪),一个成比例(缩放),往往不太能分辨出来.
    在2D空间中,有矩阵如下:
    \begin{equation*}
    \boldsymbol{H}_{x}(s) = 
    \begin{bmatrix}
    1 & 0 \\
    s & 1 \\
    \end{bmatrix}
    \end{equation*}
    \begin{equation*}
    \boldsymbol{H}_{y}(s) = 
    \begin{bmatrix}
    1 & s \\
    0 & 1 \\
    \end{bmatrix}
    \end{equation*}

    其中,x,y各自表示被固定的那个轴,s表示裁剪的大小.
    同理,在3D空间中,有:
    \begin{equation*}
    \boldsymbol{H}_{xy}(s,t) = 
    \begin{bmatrix}
    1 & 0 & 0\\
    0 & 1 & 0 \\
    s & t & 1
    \end{bmatrix}
    \end{equation*}

    \begin{equation*}
    \boldsymbol{H}_{xz}(s,t) = 
    \begin{bmatrix}
    1 & 0 & 0\\
    s & 1 & t \\
    0 & 0 & 1
    \end{bmatrix}
    \end{equation*}

    \begin{equation*}
    \boldsymbol{H}_{yz}(s,t) = 
    \begin{bmatrix}
    1 & s & t\\
    0 & 1 & 0 \\
    0 & 0 & 1
    \end{bmatrix}
    \end{equation*}
*** 5.6 Combining Transformations[组合变换]
    本章节主要讲述的是如何将各种不同的变换(旋转/缩放/投影/反射/裁剪...)组合为一个单一的矩阵.
    组合变换的一个例子是 *渲染*[rendering].想象一下在世界坐标系中有一个任意位置和方向的物体,我们的
    目的是让它在一个给定的 *摄像机*[camera] 下渲染.
    首先,我们要知道它的所有顶点坐标,并且将它们从 *本地空间*[local space] 转移到 *世界空间*[world 
    space],这个过程被叫作 *模型变换*[model transform],用 $\boldsymbol{M}_{wld\to cam}$ 表示.
    然后,我们将变换到世界坐标系的物体的顶点转换到 *摄像机空间*[camera space],这个过程被叫作 *视角变换*[view
    transform],用 $\boldsymbol{M}_{wld \to cam}$ 表示.
    总结如下:
    $\boldsymbol{P}_{wld} = \boldsymbol{P}_{obj} \boldsymbol{M}_{obj \to wld}$,
    $\boldsymbol{P}_{cam} = \boldsymbol{P}_{wld} \boldsymbol{M}_{wld \to cam} = (\boldsymbol{P}_{obj} \boldsymbol{M}_{obj \to wld}) \boldsymbol{M}_{wld \to cam}$.
    $\boldsymbol{P}_{cam} = \boldsymbol{P}_{wld} \boldsymbol{M}_{wld \to cam} = \boldsymbol{P}_{obj} (\boldsymbol{M}_{obj \to wld} \boldsymbol{M}_{wld \to cam})$.
    $\boldsymbol{P}_{cam} = \boldsymbol{P}_{wld} \boldsymbol{M}_{wld \to cam} = \boldsymbol{P}_{obj} (\boldsymbol{M}_{obj \to cam})$.
    以上是从代数角度来描述矩阵乘法,下面我们从几何的方式来了解.
    \begin{equation*}
    \boldsymbol{A}=
    \begin{bmatrix}
    -\boldsymbol{a}_{1}- \\
    -\boldsymbol{a}_{2}- \\
    -\boldsymbol{a}_{3}- \\
    \end{bmatrix},
    \boldsymbol{AB}=
    (
    \begin{bmatrix}
    -\boldsymbol{a}_{1}- \\
    -\boldsymbol{a}_{2}- \\
    -\boldsymbol{a}_{3}- \\
    \end{bmatrix}
    \boldsymbol{B})
    =
    \begin{bmatrix}
    -\boldsymbol{a}_{1} \boldsymbol{B}- \\
    -\boldsymbol{a}_{2} \boldsymbol{B}- \\
    -\boldsymbol{a}_{3} \boldsymbol{B}- \\
    \end{bmatrix}
    \end{equation*}
    在几何方式上,我们将矩阵看成是基向量的集合,而矩阵与矩阵的乘法,就分解成了向量与矩阵的乘法.
*** 5.7 Classes of Transformations[变换的种类]
    当我们讨论 *变换*[transformation]的时候,几乎就等同于在讨论 *映射*[mapping] 或者 *函数*[function].
    简而言之,所谓的 *映射* 就是这样一个规则:接受一个输入,提供一个输出.一个映射可以表示为:
    $F(a) = b$ (read "F of a euqals b")
    同样,变换也是接受一个矩阵,输出另一个矩阵.
**** Linear Transformations[线性变换]
     在映射的角度, *线性变换*[linear transformation]表示为:
     $F(a+b) = F(a) + F(b)$ 
     $F(ka) = kF(a)$
     从矩阵的线性变换来看,可表示为:
     $F(a) = aM$
     $F(a+b) = (a+b)M = aM + bM = F(a) + F(b)$ 
     $F(ka) = (ka)M = k(aM) = kF(a)$
     总结如下:
     1. 任何可以用矩阵乘法实现的变换都是线性变换.
     2. 线性变换 _不包括_ *位移*[translation].
        If $F(0) = a, a \neq 0$  then not a linear translation
     3. 一个线性变换可能会 a)使物体 *伸缩*[stretch],
        但是, b)不会让直线 *变弯*,c) 平行线仍然 *平行*.
        A linear translation may "stretch" things,but straight lines are not "warped" and parallel lines
     remain parallel.
**** Affline Transformations[仿射变换]
     *仿射变换*[affline transformation] = *线性变换*[linear transformation] + *平移*[translation]
     线性变换是仿射变换的 *子集*[subset].每个线性变换都是仿射变换,但是每个仿射变换却不一定是线性变
     换,仿射变换有如下公式:
     $\vec{v'} = \vec{v}M +b$
**** Invertible Transformations[可逆变换]
     *可逆变换*[invertible transformation],类似于对已有的变换做 *撤销*[undo]操作.
     $F^{-1}(F(a)) = F(F^{-1}(a)) = a$ 
     如果对所有的a都能满足上述等式,就说明F(a)是一个可逆变换.现在我们要考虑的是, *仿射变换*[affline 
     transformation] 是否是可逆的?
     我们知道 *仿射变换* = *线性变换* + *位移*,很明显,位移的撤销操作就是取负,那么现在问题就被简化为:
     _线性变换是否可逆_?
     从直觉上来说, *旋转* / *缩放* / *反射* / *裁剪* ,我们都可以进行撤销操作,唯独 *投影*,我们不知道怎么
     怎么搞.
     从前面章节可以知道,所有的线性变换都可以被表达成与矩阵相乘的结果,那么找线性变换的 *逆*[inverse]
     实际上就是找到矩阵的 *逆*.
     如果一个矩阵 _没有逆_,那么它就是一个 *奇异矩阵*[singular matrix].一个 *可逆矩阵* 的 *行列式*[det]
     是 _非零_ 的.
     在一个 *非奇异矩阵* 中,零向量的输入输出是 *一一对应* 的,即输入零向量必然输出零向量,而输入其他向
     量则输出其它非零向量.
     在一个 *奇异矩阵*[singular matrix] 中,零向量的输入输出是 *多对一* 的,即存在多个向量它们的输出结
     果是一个零向量,而这些向量被称作矩阵的 *零空间*[null space].
     一个 *奇异矩阵* 的基向量肯定是 *线性相关*[linearly correlation]的(因为映射是多对一的).我们知道如果
     基向量是 *线性无关*[linearly independent]的,那它是 *满秩*[full rank]的,并且空间中给定的任意向量都是唯
     一确定的.
**** Angle-Preserving Transformations
     如果一个角在转换后它的大小和方向仍然保持不变,我们就把这个变换叫做 *angle-preserving*.

     符合 *angle-preserving* 的变换有
     *平移*[translation] , *旋转*[rotation] , *统一缩放*[uniform scale].

     之所以 *反射*[reflection]变换不符合 *angle-preserving*,是因为在变换后角的方可能变成了它的 *逆*.
     所有的 *angle-preserving* 变换都是 *仿射*[affline] 和 *可逆*[invertible] 的.
**** Orthogonal Transformations[正交变换]
     *Orthogonal* 在之前已经解释过了,它表示 *互相垂直*[perpendicular] 的 *单位向量*[unit length].
     在此 *Orthogonal Matrix* 表示的是它的每个 *行向量* (即基向量) 之间是 *正交* 的.
     符合 *正交变换* 的有:
     *平移*[translation], *旋转*[rotation], *反射*[reflection].
     所有的 *正交变换* 都是 *仿射变换* 并且 *可逆*. 正交变换能保证 _不改变_ 变换后的 *角度大小*, *面积*
     , *体积*,但是却不能保证它们的正负.
**** Rigid Body Transformations[刚体变换]
     *刚体变换*[rigid body transformation] 是一种改变物体 *位置*[position], *方向*[orientation] 但是不改
     变物体 *形状*[shape] 的变换.
     这就意味着, *刚体变换* 不会改变 *角度*, *长度*, *面积* 和 *体积*.同样也意味着, *刚体变换* 满足
     *正交*[orthogonal], *angle-preserving*, *可逆*[invertible] 和 *仿射*[affline].
     从上面的说明可以感受到, *刚体变换* 是限制最多的变换,但是,在实际的游戏开发中,运用的却最多.
** Chapter 6 More On Matrices[更多关于矩阵]
*** 6.1 Determinant of a Matrix[矩阵行列式]
    对 *方阵*[square matrix]而言,这里有一个关于矩阵的特殊 *标量*[scalar] ,被叫做 *行列式*[determinant].行列式在
    线性代数中有很多有用的属性,同时它也有自己的 *几何解释*[geometric interpretations].
**** Determinant of 2 x 2 and 3 x 3 matrices[2x2和3x3矩阵的行列式]
     *方阵* M的行列式表示为 $|\boldsymbol{M}|$ ,或者也被叫做 'det M'.
     一个2 x 2 的方阵的行列式为:
     \begin{equation*}
     |\boldsymbol{M}| =
     \begin{vmatrix}
     m_{11} & m_{12} \\
     m_{21} & m_{22} 
     \end{vmatrix}
     = m_{11}m_{22} -m_{12}m_{21}
     \end{equation*}

     一个3 x 3 的方阵的行列式为:
     \begin{equation*}
     |\boldsymbol{M}| =
     \begin{vmatrix}
     m_{11} & m_{12} & m_{13} \\
     m_{21} & m_{22} & m_{23} \\
     m_{31} & m_{32} & m_{33} \\
     \end{vmatrix} 
     =
     m_{11}m_{22}m_{33} + m_{12}m_{23}m_{31} + m_{13}m_{21}m_{32} -
     m_{13}m_{22}m_{31} - m_{12}m_{21}_m_{33} - m_{11}m_{23}m_{32}
     =
     m_{11}(m_{22}m_{33} - m_{23}m_{32}) - m_{12}(m_{23}m_{31} - m_{21}m_{33}) + m_{13}(m_{21}m_{32} - m_{22}m_{31})
     \end{equation*}

     如果我们把这个3 x 3 的矩阵的行解释成三个向量,则可以表示成:

     \begin{equation*}
    |\boldsymbol{M}| =
    \begin{vmatrix}
    a_{x} & a_{y} & a_{z} \\
    b_{x} & b_{y} & b_{z} \\
    c_{x} & c_{y} & c_{z} \\
    \end{vmatrix} 
    =
    c_{z} (a_{x}b_{y} - a_{y}b_{x}) + c_{y} (a_{z}b_{x} - a_{x}b_{z}) + c_{x} (a_{y}b_{z} - a_{z}b_{y})
    =
    (\vec{a} \times \vec{b})\cdot \vec{c}
    \end{equation*}
**** Minors and Cofactors[余子式和代数余子式]
     假设M是一个r(ow)行c(olumn)列的矩阵.现在考虑从M中减去第i行和第j列,那么剩下的矩阵还有r-1行和c-1
     列.这个 *子矩阵*[submatrix]的 *行列式*[determinant] 被表示为 $M^{\{ij\}}$ ,也被叫做M的 *余子式*[minor].
     e.g
     \begin{equation*}
     \boldsymbol{M}=
     \begin{bmatrix}
     -4 & -3 & 3 \\
     0 & 2 & -2 \\
     1 & 4 & -1 \\
     \end{bmatrix}
     \Longrightarrow
     M^{\{12\}} =
     \begin{vmatrix}
     0 & -2 \\
     1 & -1 \\
     \end{vmatrix} =
     2
     \end{equation*}

     方阵M的 *代数余子式*[cofactor] 除了正负号不确定外,其他与M的 *余子式*[minor] 相同.
     $C^{\{ij\}} = (-1)^{i+j} M^{\{ij\}}$. (注意,结果是一个 *标量*[scalar])
**** Determinants of Arbitrary n x n Matrices[任意方阵的行列式]
     在这里我们使用 *代数余子式*[Cofactors]来定义 *行列式*[determinant].从前面我们知道, *代数余子式*
     [cofactor]是带符号的 *余子式*[minor].而 *行列式*[determinant]是递归的,因为行列式的结果等于任意一行
     或者一列的元素分别与对应的 *代数余子式* 相乘的结果.
     *方阵* -> M, *标量* -> (*行列式*[determinant] , *余子式*[minor] , *代数余子式*[cofactor]).
     注意,矩阵的行列式不仅是一个标量,而且它在几何上可以看成是 _矩阵向量所组成的空间的 *体积*_.
     假设选定任意 *行/列* i,则有公式如下:
     $|\boldsymbol{M}| = \sum _{j=1}^{n}m_{ij} C^{\{ij\}} = \sum _{j=1}^{n}m_{ij} (-1)^{i+j} M^{\{ij\}}$
     则3 x 3 矩阵可表示为:
     \begin{equation*}
     \begin{vmatrix}
     m_{11} & m_{12} & m_{13} \\
     m_{21} & m_{22} & m_{23} \\
     m_{31} & m_{32} & m_{33} \\
     \end{vmatrix} =
     m_{11}
     \begin{vmatrix}
     m_{22} & m_{23} \\
     m_{32} & m_{33} \\
     \end{vmatrix} -
     m_{12}
     \begin{vmatrix}
     m_{21} & m_{23} \\
     m_{31} & m_{33} \\
     \end{vmatrix} +
     m_{13}
     \begin{vmatrix}
     m_{21} & m_{22} \\
     m_{31} & m_{32} \\
     \end{vmatrix}
     \end{equation*}
     4 x 4 矩阵可表示为:
     \begin{equation*}
     \begin{vmatrix}
     m_{11} & m_{12} & m_{13} & m_{14}\\
     m_{21} & m_{22} & m_{23} & m_{24}\\
     m_{31} & m_{32} & m_{33} & m_{34}\\
     m_{41} & m_{42} & m_{43} & m_{44}\\
     \end{vmatrix} =
     m_{11}
     \begin{vmatrix}
     m_{22} & m_{23} & m_{24}\\
     m_{32} & m_{33} & m_{34}\\
     m_{42} & m_{43} & m_{44}\\
     \end{vmatrix} -
     m_{12}
     \begin{vmatrix}
     m_{23} & m_{24} & m_{21}\\
     m_{33} & m_{34} & m_{31}\\
     m_{43} & m_{44} & m_{41}\\
     \end{vmatrix} +
     m_{13}
     \begin{vmatrix}
     m_{24} & m_{21} & m_{22}\\
     m_{34} & m_{31} & m_{32}\\
     m_{44} & m_{41} & m_{42}\\
     \end{vmatrix} -
     m_{14}
     \begin{vmatrix}
     m_{21} & m_{22} & m_{23}\\
     m_{31} & m_{32} & m_{33}\\
     m_{41} & m_{42} & m_{43}\\
     \end{vmatrix}
     \end{equation*}
     展开后,可以得到:
     \begin{equation*}
     \begin{align}
     m_{11}
     [
     m_{22}(m_{33}m_{44} - m_{34}m_{43}) + 
     m_{23}(m_{34}m_{42} - m_{32}m_{44}) +
     m_{24}(m_{32}m_{43} - m_{33}m_{42})
     ]
     \\-
     m_{12}
     [
     m_{23}(m_{34}m_{41} - m_{31}m_{44}) + 
     m_{24}(m_{31}m_{43} - m_{33}m_{41}) +
     m_{21}(m_{33}m_{44} - m_{34}m_{43})
     ]
     \\+
     m_{13}
     [
     m_{24}(m_{31}m_{42} - m_{32}m_{41}) + 
     m_{21}(m_{32}m_{44} - m_{34}m_{42}) +
     m_{22}(m_{34}m_{41} - m_{31}m_{44})
     ]
     \\-
     m_{14}
     [
     m_{21}(m_{32}m_{43} - m_{33}m_{42}) + 
     m_{22}(m_{33}m_{41} - m_{31}m_{43}) +
     m_{23}(m_{31}m_{42} - m_{32}m_{41})
     ]
     \end{align}
     \end{equation*}

     由此,我们简要说明一些行列式的相关特性: (从行列式的 _几何解释_ 来理解)
     - *单位矩阵*[identity matrix]的行列式等于1.
       $|\boldsymbol{I}| = 1$

     - 矩阵乘积的行列式等于各个矩阵行列式相乘.
       $\boldsymbol{|A||B| = |A||B|}$
       $\boldsymbol{|M_{1} M_{2} ... M_{n}| = |M_{1}| |M_{2}| ... |M_{n}|}$

     - 转置矩阵与原矩阵的行列式相等.
       $\boldsymbol{|M^T| } = \boldsymbol{|M|}$

     - 只要矩阵内有 _任何一行或者一列_ 为0,则矩阵的行列式结果为0.
     \begin{equation*}
     \begin{vmatrix}
     ? & ? & ? & ? \\
     0 & 0 & 0 & 0 \\
     ? & ? & ? & ? \\
     ? & ? & ? & ? \\
     \end{vmatrix}
     =
     \begin{vmatrix}
     ? & ? & 0 & ? \\
     ? & ? & 0 & ? \\
     ? & ? & 0 & ? \\
     ? & ? & 0 & ? \\
     \end{vmatrix}
     = 0
     \end{equation*}

     - *互换*[exchanging] 矩阵中的某行或某列会改变行列式的正负.
     \begin{equation*}
     \begin{vmatrix}
     m_{11} & m_{12} & m_{13} \\
     m_{21} & m_{22} & m_{23} \\
     m_{31} & m_{32} & m_{33} \\
     \end{vmatrix}
     = -
     \begin{vmatrix}
     m_{11} & m_{12} & m_{13} \\
     m_{31} & m_{32} & m_{33} \\
     m_{21} & m_{22} & m_{23} \\
     \end{vmatrix}
     \end{equation*}

     - 把k倍大小的行(或列)添加到另一个矩阵的行(或列)中,并不会改变行列式的值.
     \begin{equation*}
     \begin{vmatrix}
     m_{11} & m_{12} & m_{13} \\
     m_{21} & m_{22} & m_{23} \\
     m_{31} & m_{32} & m_{33} \\
     \end{vmatrix}
     =
     \begin{vmatrix}
     m_{11} & m_{12} & m_{13} \\
     m_{31}+km_{21} & m_{32}+km_{22} & m_{33}+km_{22}\\
     m_{21} & m_{22} & m_{23} \\
     \end{vmatrix}
     \end{equation*}
**** Geometric Interpretation of Determinant[行列式的几何解释]
     矩阵行列式有一个有趣的几何解释.
     在2D中,矩阵行列式等于 _向量围成的平行四边形的带符号面积_.(如果行列式结果为负,表示围成的平行四
     边形相对于原点 *翻转*[flipped]了).
     在3D中,矩阵行列式等于 _向量围成的平行六面体的体积_.(如果行列式结果为负,表示围成的是 *反射*
     [reflected] 后的平行四边形,同样也是 *翻转*[turned inside out]了.
     行列式与矩阵变换的大小变化有关.行列式的绝对值表示的是矩阵变换后的 *面积*[area](2D) 或者 *体积*
     [volume](3D).而带的符号(正负)则表明了该矩阵中是否包含了 *反射* 或者 *投影*.
     因而我们可以通过观察矩阵行列式来判断该矩阵的类型.
*** 6.2 Inverse of a Matrix[矩阵的逆]
     除了矩阵的 *行列式*[determinant] 要求矩阵必须是 *方阵*[square matrix] 外,矩阵的 *逆*[inverse]也有
     同样的要求.
     假设存在方阵 $\boldsymbol{M}$,则方阵的逆为$\boldsymbol{M^{-1}}$,则存在关系:
     $\boldsymbol{MM^{-1}} = \boldsymbol{M^{-1}M} = \boldsymbol{I}$
     并不是所有的矩阵都有 *逆*.一个明显的例子是一行或者一列全是0的矩阵无论与其他什么矩阵相乘,相关
     行或列的结果都只能是0.
     一个 _存在逆矩阵_ 的矩阵被叫做 *invertible*[可逆矩阵] 或者 *nonsingular*[非奇异矩阵].
     det != 0 --> 可逆矩阵 --> 非奇异矩阵 --> 线性无关
     一个 _不存在逆矩阵_ 的矩阵被叫做 *noneinvertible*[不可逆矩阵] 或者 *singular*.
     det ==0 --> 不可逆矩阵 ---> 奇异矩阵 --> 线性相关

     对任何 *可逆矩阵* 来说,存在 $\vec{v}M = 0$ 的原因只可能是 $\vec{v} = 0$.
     进一步来说, *可逆矩阵* 的行或者列之间必然是 *线性无关*[linearly independent]的.
**** The Classical Adjoint[伴随矩阵]
     矩阵的 *逆*[inverse] 是通过 *伴随矩阵*[classical adjoint]来计算的.矩阵M的伴随矩阵写做 $adj \boldsymbol{M}$,被定
义为由 _M的余子式组成的矩阵的转置_ (the transpose of the matrix of cofactors of M).
     假设有一 3 x 3 矩阵如下:
\begin{equation*}
\boldsymbol{M} =
\begin{bmatrix}
-4 & -3 & 3 \\
0 & 2 & -2 \\
1 & 4 & -1
\end{bmatrix}
\end{equation*}

     1) 计算M的 *余子式*[cofactors],
        $C^{\{11\}} = + 6 = 6$, ... , ... , 
        $C^{\{33\}} = +(-8) = -8$
     2) 转置矩阵 $adj \boldsymbol{M}$ 就表达为:
     \begin{equation*}
     adj \boldsymbol{M} =
     \begin{vmatrix}
     C^{\{11\}} & C^{\{12\}} & C^{\{13\}}\\
     C^{\{21\}} & C^{\{22\}} & C^{\{23\}}\\
     C^{\{31\}} & C^{\{32\}} & C^{\{33\}}\\
     \end{vmatrix}^T
     \\=
     \begin{vmatrix}
     6 & -2 & -2 \\
     9 & 1 & 13 \\
     0 & -8 & -8
     \end{vmatrix}^T
     \\=
     \begin{vmatrix}
     6 & 9 & 0 \\
     -2 & 1 & -8 \\
     -2 & 13 & -8
     \end{vmatrix}
     \end{equation*}
**** Matrix Inverse - Official Linear Algebra Rules[可逆矩阵在线性代数中的规则]
     计算矩阵的逆的公式如下:
     $\boldsymbol{M}^{-1} = \frac{adj \boldsymbol{M}} {\boldsymbol{|M|}}$.
     从公式可以看出来,$\boldsymbol{|M|}$ 是不能为0的.这就是我们为什么说行列式为0的矩阵时不可逆矩阵的原因.
     还有其他计算矩阵的逆的方法,一个典型的方法是 *高斯消元法*[Gaussian elimination].
     现在我们来总结一下矩阵的逆的相关信息:
     - 矩阵的逆的逆就是原矩阵.
       $(\boldsymbol{M^{-1}})^{-1} = \boldsymbol{M}$
     - 单位矩阵的逆就是它自己.
       $\boldsymbol{I^{-1}} = \boldsymbol{I}$
     - 转置矩阵的逆等于逆矩阵的转置.
       $(\boldsymbol{M^{T}})^{-1} = (\boldsymbol{M^{-1}})^{T}$
     - 矩阵积的逆等于反向的矩阵的逆的积
       $\boldsymbol{(AB)^{-1}} = \boldsymbol{B^{-1}A^{-1}}$,
       也即是:
       $\boldsymbol{(M_{1}M_{2}...M_{n})^{-1}} = \boldsymbol{M_{n}^{-1} M_{n-1}^{-1} ... M_{1}^{-1}}$
     - 矩阵的逆的行列式值等于原矩阵行列式的倒数.
       $\boldsymbol{|M^{-1}| = 1 / |M|}$
**** Matrix Inverse - Geometric Interpretation[可逆矩阵的几何解释]
     可逆矩阵的几何解释,直观上来看很容易理解,根据公式:
     $\boldsymbol{(vM)M^{-1} = v(MM^{-1}) = vI = v}$.
     可知,可逆矩阵其实是在对矩阵的变换做一个 *撤销*[undo]操作.
*** 6.3 Orthogonal Matrices[正交矩阵]
**** Orthogonal Matrices - Official Linear Algebra Rules[正交矩阵在线性代数中的规则]
     定义如下: _当且仅当_ *方阵* 与其 *转置矩阵*[transpose] 之 *积*[product] 是 *标准矩阵*[identity matrix]
时,我们才说该矩阵是 *正交矩阵*[orthogonal matrix].注意这里的符号 $\Longleftrightarrow$ 表示两者是可以互相推导的.
     $\boldsymbol{M(orthogonal)} \Longleftrightarrow  \boldsymbol{MM^{T} = I}$
     同时,由上一节得到的公式 $\boldsymbol{MM^{-1} = I}$,可得:
     $\boldsymbol{M(orthogonal)} \Longleftrightarrow  \boldsymbol{M^{T} = M^{-1}}$
     *注意*,这是一个 _超级有用_ 的公式,因为 *矩阵的逆*[inverse of a matrix] 会经常被用到,而 *正交矩阵*
[orthogonal matrices]在3D图形中出现的非常频繁.一个典型的例子就是 *旋转* 和 *反射* 变换的矩阵都是正
交的.如果我们知道一个矩阵是正交的,那么我们就可以使用矩阵的 *转置* 而不是矩阵的 *逆* 来做计算(因为
矩阵的逆需要进行更多的运算).
**** Orghogonal Matrices - Geometric Interpretation[正交矩阵的几何解释]
     在很多情况下,我们是先知道矩阵会做什么变换,进而使用该矩阵做出变换的操作.但是,如果我们事先不知道
这是个进行什么变换的矩阵,比如只是告诉你有一个正交矩阵,会出现什么情况呢?
     现在,假设存在一个 3 x 3 的矩阵M,根据前面的公式,可推出如下结果:
     $\boldsymbol{MM^{T} = I}$,
     \begin{equation*}
     \begin{bmatrix}
     m_{11} & m_{12} & m_{13} \\
     m_{21} & m_{22} & m_{23} \\
     m_{31} & m_{32} & m_{33} \\
     \end{bmatrix}
     \begin{bmatrix}
     m_{11} & m_{21} & m_{31} \\
     m_{12} & m_{22} & m_{32} \\
     m_{13} & m_{23} & m_{33} \\
     \end{bmatrix} =
     \begin{bmatrix}
     1 & 0 & 0 \\
     0 & 1 & 0 \\
     0 & 0 & 1 \\
    \end{bmatrix}
     \end{equation*}
     用向量 $r_{1},r_{2},r_{3}$ 分别表示M的行,则有:
     \begin{equation*}
     r_{1} =
     \begin{bmatrix}
     m_{11} & m_{12} & m_{13} \\
     \end{bmatrix}
     r_{2} =
     \begin{bmatrix}
     m_{21} & m_{22} & m_{23} \\
     \end{bmatrix}
     r_{3} =
     \begin{bmatrix}
     m_{31} & m_{32} & m_{33} \\
     \end{bmatrix}
     \end{equation*}
     \begin{equation*}
     \boldsymbol{M} =
     \begin{bmatrix}
     \boldsymbol{-r1-} \\
     \boldsymbol{-r2-} \\
     \boldsymbol{-r3-} \\
     \end{bmatrix}
     \end{equation*}
     根据以上条件,则有:
     $r_{1} \cdot r_{1} = 1$, $r_{1} \cdot r_{2} = 0$, $r_{1} \cdot r_{3} = 0$,
     $r_{2} \cdot r_{1} = 0$, $r_{2} \cdot r_{2} = 1$, $r_{2} \cdot r_{3} = 0$,
     $r_{3} \cdot r_{1} = 0$, $r_{3} \cdot r_{2} = 0$, $r_{3} \cdot r_{3} = 1$.
     从上面我们可以得出如下结论:
     - 只有 *单位向量*[unit vector]与自己的点积结果才可能等于1.
     - 如果两个向量的点积结果为0,原因只能是这两个向量互相 *垂直*[perpendicular].

     所以,如果一个矩阵是 *正交矩阵*,那么:
     - 矩阵的每行(列)都是 *单位向量*.
     - 矩阵的行(列)向量必然互相 *垂直*.
     之前我们就说过 *正交基*[orthogonal basis]在3D图形学中极其有用,而现在我们又了解了它的另一特性,
即 _正交矩阵的转置与它的逆相等_.
     由于点积符合 *交换律*[commutative],所以上面的9个等式实际上可以简化为6个.
     $r_{1} \cdot r_{1} = 1$, $r_{1} \cdot r_{2} = 0$, $r_{1} \cdot r_{3} = 0$,
     $r_{2} \cdot r_{2} = 1$, $r_{2} \cdot r_{3} = 0$,
     $r_{3} \cdot r_{3} = 1$.
     通常情况下,在考虑计算矩阵的 *逆* 时,最好的情况是提前知道该矩阵是否是 *正交矩阵*.如果在不知道是
否正交的情况下先判断正交会浪费很多时间,就算判断成功,再转置该矩阵的情况下与直接计算矩阵的逆效率
上也差不了多少了.而如果失败,那么我们用来判断正交的时间就浪费了.

     *注意*,这里详细的解释一些术语.
     如果一组 *基向量*[basis vecotrs] 是互相 *垂直*[perpendicular]的,我们就说它们是 *正交*[orthogonal]
的,更进一步,如果基向量还是 *单位向量*[unit vector],这组向量就叫做 *标准正交基*[orthonormal basis].
由此,一个 *正交矩阵*[orthogonal matrix]的行或者列都是 *标准正交基向量*[orthonormal basis vectors].但是
反过来看,一组 *正交基向量* 并不保证能构成一个 *正交矩阵* (除非基向量是 *标准正交基*).
     *orthonormal* --> *标准正交*,
     *orthogonal* --> *正交*.
**** Orthogonalizing a Matrix[矩阵正交化]
     构建 *正交基向量*[orthogonal basis vectors]的标准算法叫做 *Gram-Schimidt orthogonalization*.基
本的想法是按顺序浏览基向量.
     For each basis vector, we subtract off the portion of that vector that is parallel to the proceeding
basis vectors,which must result in a perpendicular vector.
     对每个基向量而言,我们减去它平行于下一个基向量的那部分,就一定会得到一个垂直的向量.
     假设存在一个$3 \times 3$ 的矩阵$\boldsymbol{M}$ ,它的行向量分别用 $r_{1},r_{2},r_{3}$ 表示,那么这一组
正交的行向量可以被表示为:
     $\boldsymbol{r^{'}_{1} \Leftarrow r_{1}}$,
     $\boldsymbol{r^{'}_{2} \Leftarrow r_{2} - \frac{r_{2} \cdot r^{'}_{1}} {r^{'}_{1} \cdot r^{'}_{1}} r^{'}_{1}}$,
     $\boldsymbol{r^{'}_{3} \Leftarrow r_{3} - \frac{r_{3} \cdot r^{'}_{1}} {r^{'}_{1} \cdot r^{'}_{1}} r^{'}_{1} - \frac{r_{3} \cdot r^{'}_{2}} {r^{'}_{2} \cdot r^{'}_{2}} r^{'}_{2}}$
     在应用这些步骤后,会得到互相垂直的向量 $r_{1},r_{2},r_{3}$,从而形成一组 *正交基*,虽然它们不一定是 *单位向量*.
而因为我们需要一组 *标准正交基*[orthonormal basis]来构造 *正交矩阵*[orthogonal matrix],所以我们必须
要 *标准化*[normalize] 这些向量.
     而在3D空间中,我们还能使用一个特殊的技巧-*叉积*[cross product]来初始化第三个基向量.
     $\boldsymbol{r^{'}_{3} \Leftarrow r^{'}_{1} \times r^{'}_{2}}$
*** 6.4 4 x 4 Homogeneous Matrices[齐次矩阵]
    在前面的章节里我们只涉及了2D和3D向量,现在我们将介绍4D向量,也被叫做 *齐次空间*[homogeneous 
coordinate].
    首先,我们要知道 *齐次*[homogeneous]是什么意思,其实 *齐次坐标*,也叫 *投影坐标*,是指一个用于投影几
何的坐标系统.
    使用齐次矩阵的原因很简单,在3D空间的变换中需要频繁使用 *位移*[translation],但是3D矩阵无法实现
*仿射变换*[affline transformation],而在4x4的齐次矩阵中,则能满足 *仿射变换* (位移 + 线性变换).
**** 4D Homogeneous Space[4D齐次空间] 
     4D向量由四部分组成(x,y,z,w),其中w通常被叫做 *齐次坐标*[homogeneous coordinate].
     为了理解标准的物理3D空间是怎么被扩展成4D空间的,我们先来理解2D空间中的齐次坐标,在此我们把它表
示为$(x,y,w)$.我们把一个标准的2D平面放在一个3D空间中,假设平面$w=1$,就像2D的点$(x,y)$ 在齐
次坐标空间中就是$(x,y,1)$.
     而对于那些不在 *平面*[plane] $w =1$ 的点,则可以通过除以 $w$ 来投影到相关的2D坐标上.所以齐次坐标
$(x,y,w)$ 就被映射成了2D的点 $(x/w,y/w)$.
     对任何2D中给定的点$(x,y)$,在齐次坐标空间中都有无数相关的点,所有的格式$(kx,ky,k)$,都证明$k \neq 0$.
     这些点穿过齐次坐标,构成了一条线.
     当$w=0$,除法是未定义的并且不能在其中找到相关的点.但是可以把$(x,y,0)$解释成一个 _无限远的点_,它
被定义为 *方向*[orientation] 而不是 *位置*[location].
     当我们想从概念上区别 *点*[points]和 *向量*[vector]时, 记住 $w \neq 0$ 时,代表的是 *点*[points],而
$w=0$ 时,代表的是 *向量*[vector].
**** 4 x 4 Translation Matrices[位移矩阵]
     由于3 x 3 的矩阵只能表示 *线性变换*[linear transformation],而 *位移*[translation]又是在实际应用里
频繁遇到的情况,所以为了包含这两种变换,我们需要能满足 *仿射变换*[affline transformation]的矩阵.而为
了满足这个要求,我们需要将3 x 3的矩阵扩展成 4 x 4 的矩阵.
     假设 $w = 1$,那么一个3D向量$[x,y,z]$,在4D中就可以被表示为$[x,y,z,1]$,而一个矩阵则转换如下:
\begin{equation*}
\begin{bmatrix}
m_{11} & m_{12} & m_{13} \\
m_{21} & m_{22} & m_{23} \\
m_{31} & m_{32} & m_{33} \\
\end{bmatrix}
\Rightarrow
\begin{bmatrix}
m_{11} & m_{12} & m_{13}  & 0\\
m_{21} & m_{22} & m_{23} & 0\\
m_{31} & m_{32} & m_{33} & 0\\
0 & 0 & 0 & 1
\end{bmatrix}
\end{equation*}
    当我们让向量与矩阵相乘时,有如下结果:
\begin{equation*}
\begin{bmatrix}
x & y & z\\
\end{bmatrix}
\begin{bmatrix}
m_{11} & m_{12} & m_{13} \\
m_{21} & m_{22} & m_{23} \\
m_{31} & m_{32} & m_{33} \\
\end{bmatrix} 
=
\begin{bmatrix}
xm_{11}+ym_{21}+zm_{31} &
xm_{12}+ym_{22}+zm_{32} &
xm_{13}+ym_{23}+zm_{33}
\end{bmatrix}
\end{equation*}

\begin{equation*}
\begin{bmatrix}
x & y & z & 1\\
\end{bmatrix}
\begin{bmatrix}
m_{11} & m_{12} & m_{13} & 0\\
m_{21} & m_{22} & m_{23} & 0\\
m_{31} & m_{32} & m_{33} & 0\\
0 & 0 & 0 & 1\\
\end{bmatrix} 
=
\begin{bmatrix}
xm_{11}+ym_{21}+zm_{31} &
xm_{12}+ym_{22}+zm_{32} &
xm_{13}+ym_{23}+zm_{33} &
1
\end{bmatrix}
\end{equation*}
    有趣的地方来了,从上面的矩阵来看,我们可以在第四行上加入 *平移*[translation].而方法是将 *平移* 当作
矩阵加法.
\begin{equation*}
\begin{bmatrix}
x & y & z & 1\\
\end{bmatrix}
\begin{bmatrix}
1 & 0 & 0 & 0 \\
0 & 1 & 0 & 0 \\
0 & 0 & 1 & 0 \\
\Delta x & \Delta y & \Delta z & 1
\end{bmatrix} 
=
\begin{bmatrix}
x+\Delta x & y+\Delta y & z+\Delta z & 1
\end{bmatrix}
\end{equation*}
    这个矩阵加法依然是 *线性变换*[linear transformation].在4D中,矩阵加法并不能代替 *位移*[translation],
并且4D的零向量总会变换回零向量.而之所能成功的原因是我们实际上在 *裁剪*[shearing] 4D空间,想想之前
我们看过的裁剪矩阵,在4D中做 *裁剪*,展现在3D空间的效果就是 *位移*.(想想3D空间中裁剪,2D空间的表现)
    现在考虑如何完成旋转和平移.令矩阵 $\boldsymbol{R}$ 为 *旋转矩阵*,矩阵 $\boldsymbol{T}$ 为 *位移矩阵*,则有等式如下:
\begin{equation*}
\boldsymbol{R} =
\begin{bmatrix}
r_{11} & r_{12} & r_{13} & 0 \\
r_{21} & r_{22} & r_{23} & 0 \\
r_{31} & r_{32} & r_{33} & 0 \\
0 & 0 & 0 & 1 \\
\end{bmatrix},
\boldsymbol{T} =
\begin{bmatrix}
1 & 0 & 0 & 0 \\
0 & 1 & 0 & 0 \\
0 & 0 & 1 & 0 \\
\Delta x & \Delta y & \Delta z & 1 \\
\end{bmatrix}.
\end{equation*}
    现在我们让向量 $\vec{v}$ 来进行 *旋转* + *平移* 变换,有等式:
    $\vec{v}^{'} = \vec{v} \boldsymbol{RT} = \vec{v} \boldsymbol{(RT)} = \vec{v} \boldsymbol{M}$
    可得 $\boldsymbol{M}$ 如下:
    \begin{equation*}
    \boldsymbol{M=RT=}
    \begin{bmatrix}
     r_{11} & r_{12} & r_{13} & 0 \\
     r_{21} & r_{22} & r_{23} & 0 \\
     r_{31} & r_{32} & r_{33} & 0 \\
     \Delta x & \Delta y & \Delta z & 1\\
    \end{bmatrix}
    \end{equation*}

    仔细观察,其实矩阵 $\boldsymbol{M}$ 由三部分组成, *旋转矩阵*, *平移矩阵*,以及最右边的向量.那么,我们
就可以将其化简为:
\begin{equation*}
\boldsymbol{M=}
\begin{bmatrix}
R & 0 \\
T & 1 \\
\end{bmatrix}
\end{equation*}
    让我们先考虑 *无穷远点*[points at infinity]的情况$(x,y,z,w)$,其中 $w=0$.
    \begin{euqation*}
    \begin{bmatrix}
    x & y & z & 0 \\
    \end{bmatrix}
     \begin{bmatrix}
     r_{11} & r_{12} & r_{13} & 0 \\
     r_{21} & r_{22} & r_{23} & 0 \\
     r_{31} & r_{32} & r_{33} & 0 \\
     0 & 0 & 0 & 1\\
    \end{bmatrix}
    =
     \begin{bmatrix}
     xr_{11} + yr_{21} + zr_{31} & xr_{12} + yr_{22} + zr_{32} & xr_{13} + yr_{23} + zr_{33} & 0\\
    \end{bmatrix}
    \end{euqation*}
    从上面的线性变换结果可以看出,向量$(w=0)$ 与矩阵相乘,最终得到的是形如 $[x^{'},y^{'},z^{'},0]$ 的结果.
    如果我们再加入 *位移变换*,结果如下:
     \begin{euqation*}
    \begin{bmatrix}
    x & y & z & 0 \\
    \end{bmatrix}
     \begin{bmatrix}
     r_{11} & r_{12} & r_{13} & 0 \\
     r_{21} & r_{22} & r_{23} & 0 \\
     r_{31} & r_{32} & r_{33} & 0 \\
     \Delta x & \Delta y & \Delta z & 1\\
    \end{bmatrix}
    =
     \begin{bmatrix}
     xr_{11} + yr_{21} + zr_{31} & xr_{12} + yr_{22} + zr_{32} & xr_{13} + yr_{23} + zr_{33} & 0\\
    \end{bmatrix}
    \end{euqation*}
    可见,在$w=0$ 的情况下, *位移* 变换是无效的.所以,这里的 $w$ 的值就成了一个左右 *位移* 的参数.这在实
际应用中非常的频繁,因为 *位移* 的是一些表示 *位置* 的向量,而一些仅仅表示 *方向* 的向量(如 *法线*
[surface normal]),是不应该被移动的.
    总结一下就是,
    第一种情况,在 $w=1$ 的时候,是作为 *点*[points],表示 *位置*[location]信息,进行位移.
    第二种情况,在 $w=0$ 的时候,是作为 *向量*[vector],表示 *方向*,不进行位移.
    虽然说最右边的 $[0,0,0,1]^T$ 没有什么实际意义,因为一个$4 \times 3$ 的矩阵就能完成 *线性变换* + *平移*.
但是,由于矩阵的运算和方阵的性质更方便计算,采用 $4 \times 4$ 矩阵是更优的选择.
**** General Affine Transformations[仿射变换]
    第五章介绍了 *线性变换*[linear transformation] 中的几种基本变换,而没有考虑 *位移*[translation].主
要原因在于 $3 \times 3$ 的矩阵只能表示 *线性变换*.现在我们的装备已经升级了:),通过 $4 \times 4$ 矩阵,我们现在已经
能完成 *仿射变换*[affine transformation]了.
     比如:
      - rotation about an axis that does not pass through the origin.
      - scale about a plane that does not pass through the origin.
      - reflection about a plane that doest not pass through the origin.
      - otrhographic projection onto a plane that does not pass through the origin.
     基本的做法是,先位移到原点,进行线性变换,再撤销位移.假设位移到原点的变换矩阵为 $T$ ,旋转矩阵为$R$,
再位移回之前的位置就是 $T^{-1}$.
     那么,我们有矩阵如下:
\begin{equation*}
\begin{align*}
\boldsymbol{T}=
\begin{bmatrix}
1 & 0 & 0 & 0 \\
0 & 1 & 0 & 0 \\
0 & 0 & 1 & 0 \\
-p_{x} & -p_{y} & -p_{z} & 1
\end{bmatrix} =
\begin{bmatrix}
\boldsymbol{I} & 0 \\
\boldsymbol{-p} & 1 \\
\end{bmatrix}
\\
\boldsymbol{R}=
\begin{bmatrix}
r_{11} & r_{12} & r_{13} & 0 \\
r_{21} & r_{22} & r_{23} & 0 \\
r_{31} & r_{32} & r_{33} & 0 \\
0 & 0 & 0 & 1 \\
\end{bmatrix} =
\begin{bmatrix}
\boldsymbol{R_{3 \times 3}} & 0 \\
0 & 1
\end{bmatrix}
\\
\boldsymbol{T^{-1}=}
\begin{bmatrix}
1 & 0 & 0 & 0 \\
0 & 1 & 0 & 0 \\
0 & 0 & 1 & 0 \\
p_{x} & p_{y} & p_{z} & 1
\end{bmatrix} =
\begin{bmatrix}
\boldsymbol{I} & 0 \\
\boldsymbol{p} & 1 \\
\end{bmatrix}
\end{align*}
\end{equation*}
    化简后,可得:
    \begin{equation*}
    \boldsymbol{TRT^{-1}} =
    \begin{bmatrix}
    \boldsymbol{I} & 0 \\
    \boldsymbol{-p} & 1 \\
    \end{bmatrix}
    \begin{bmatrix}
    \boldsymbol{R_{3 \times 3}} & 0 \\
    0 & 1
    \end{bmatrix}
    \begin{bmatrix}
    \boldsymbol{I} & 0 \\
    \boldsymbol{p} & 1 \\
    \end{bmatrix}=
    \begin{bmatrix}
    \boldsymbol{R_{3 \times 3}} & 0 \\
    \boldsymbol{-p(R_{3 \times 3})+p} & 1
    \end{bmatrix}.
    \end{equation*}
    从等式可以看出, 只有 *位移矩阵* 发生了变化.
    现在 "*齐次空间*" 的作用仅仅体现在实现 *仿射变换*.之所以我们要在这里加引号,是因为$w$的值总是取1(
或者0),在下一节将讨论更多的 $w$ 的取值所展现的意义.
*** 6.5 4 x 4 Matrices and Perspective Projection[矩阵和透视投影]
    当我们在讨论投影时,通常讨论的是两种情况: 
    *透视投影*[perspective projection] 和 *正交投影*[orthographic projection].
    *正交投影* 也叫 *平行投影*[parallel projection],原因就在于物体投影前后是平行的.
    *projection plane*[投影平面],物体投射到的平面.
    *projector* -> 代指从原物体的点到对应的投影平面上的点 _连成的直线_.
    *平行投影* 使用平行的 *projectors*.
    *透视投影* 中, *projectors* 形成的直线交于一点,改点被叫做 *投影中心*[center of projection].
    两者真正的区别在不同的距离上,在 *正交投影* 中,由于 *projector* 是平行的,所以距离的远近不改变投影
的大小,而在 *透视投影* 中, *投影中心* 点的位置不同,将会对投影大小产生重大的影响,这种视觉差异被叫做
*透视收缩*[foreshortening].
**** A Pinhole Camera[针孔相机]
     *透视投影* 在3D中之所以如此重要,是因为和我们人眼的机制一致.实际上人眼更为复杂,因为每只眼睛的投
影表面(视网膜)都不是平坦的.
     *针孔相机*[pinhole camera]的成像原理与我们视网膜的成像原理是一致的.对任意一点 $p$,存在对应的投影
     平面中的点 $p^{'}$,其中$p$ 是穿过了 *针孔*[pinhole] 再投影到投影平面的.假设 *针孔* 到投影平面的距离为 $d$,
平面为$z$ ,显然可得: $z = -d$.
     又因为相似三角形的边对应成比例,因而有:
     \begin{equation*}
     \frac{-p_{y}^{'}}{d} = \frac {p_{y}}{z} \Rightarrow p_{y}^{'} = \frac{-dp_{y}} {z}.
     \end{equation*}
     同理,有 $p^{'}_{x} = \frac{-dp_{x}}{z}$.
     由此可得:
     \begin{equation*}
     \boldsymbol{p} =
     \begin{bmatrix}
     x & y  & z \\
     \end{bmatrix}
     \Rightarrow
     \boldsymbol{p^{'}} = 
     \begin{bmatrix}
     -dx/z & -dy/z  & -d \\
     \end{bmatrix}
     \end{equation*}
     在另一种情况下 $(z = d)$,即 _投影平面在投影中心之前_,那么我们的距离 $d$ 就不再为负,则有:
      \begin{equation*}
     \boldsymbol{p} =
     \begin{bmatrix}
     x & y  & z \\
     \end{bmatrix}
     \Rightarrow
     \boldsymbol{p^{'}} = 
     \begin{bmatrix}
     dx/z & dy/z  & d \\
     \end{bmatrix}
     \end{equation*}
**** Perspective Projection Matrices[透视投影矩阵]
     我们知道4D齐次矩阵转换到3D需要用到除法.我们可以在一个 $4 \times 4$ 的矩阵中构造 *透视投影*.在4D齐次
矩阵中,向量表示为 $[x,y,z,w]$ ,假设 $w=1$ ,根据上一节公式:
     \begin{equation*}
     \boldsymbol{p} =
     \begin{bmatrix}
     x & y  & z \\
     \end{bmatrix}
     \Rightarrow
     \boldsymbol{p^{'}} = 
     \begin{bmatrix}
     dx/z & dy/z  & d \\
     \end{bmatrix} = 
     \begin{bmatrix}
     dx & dy  & dz \\
     \end{bmatrix}     
     =
     \frac 
     {
     \begin{bmatrix}
     x & y  & z \\
     \end{bmatrix}     }
     {z/d}
     \end{equation*}
     则有4D向量$[x,y,z,z/d]$,考虑到 $\vec{v}^{'} = \vec{v}M$,则有:
     \begin{equation*}
     \begin{bmatrix}
     x & y & z & 1
     \end{bmatrix}
     M=
      \begin{bmatrix}
     x & y & z & z/d
     \end{bmatrix},
     M = 
      \begin{bmatrix}
      1 & 0 & 0 & 0 \\
      0 & 1 & 0 & 0 \\
      0 & 0 & 0 & 1/d \\
      0 & 0 & 0 & 0
     \end{bmatrix}.
     \end{equation*}
     矩阵$M$ 即是 *透视投影矩阵*.
     总结如下:
     - 与 *透视投影矩阵* 相乘并不能真正表示 *透视变换*.它只是在为w计算适当的分母.
     - w可以取很多值,不同的值有不同的意义.
     - 尽管$4 \times 4$ 的齐次矩阵很复杂,但是却能满足在一个矩阵里同时进行 *线性变换* 和 *位移*.同时,投影到
非坐标轴相关的平面也成为了可能.
     - *投影矩阵* 在实际的渲染管线中做的工作不只是把z复制进w.
       a. 在很多图形系统中,把w=1当作 *depth buffring*[深度缓存]中最远的平面.通常w的范围在[0,1].
       b. 摄像机的 *FOV* (field of view)通常通过 *投影矩阵* 缩放 $x,y$ 值来调整.
** Chapter 7 Polar Coordinate Systems[极坐标系]
   笛卡尔坐标系并不是唯一与空间和位置相关的坐标系.另一个备选的坐标系叫 *极坐标系* [polar coordinate
system].之所以要介绍它,是因为在游戏开发中,某些模块(AI,摄像机)会经常用到.
*** 7.1 2D Polar Space[2D极坐标空间]
    这段会在2D中介绍极坐标的一些基本概念,以对极坐标有一个直观的了解.
**** Locating Points by Using 2D Polar Coordinates[使用2D极坐标来确定点]
     在2D笛卡尔坐标系中,通过 *原点*[origin]来确定坐标系的 *位置*[position],而通过 *原点* 的两个 *轴*[axis]
,确定了坐标系的 *方向*[orientation].
     同样,在2D极坐标系中也有 *原点*,它被用来确定坐标系的中心.一个极坐标系只有一个 *轴*,被叫做 *极坐
标轴*[polar axis],可以把它想象成从原点发出来的射线.习惯上让极坐标轴指向右边(像笛卡尔坐标系里的y轴).
     通过上面的信息,我们可以知道一个极坐标的位置由两个参数确定,一是$r$(半径),一是$\theta$(角度).从而我们可以
用 $(r,\theta)$ 来表示任意在2D极坐标空间中的点的位置.
     以极坐标轴为起点, *逆时针*[counter clockwise] 方向为 *正*[positive], *顺时针* 方向为 *负*[negative],
以此来确定 *角度*[angle] 的大小.
     以点与原点的距离来确定半径 $r$ 的大小.
     总结就是, $r$ 定义了点到原点的距离, $\theta$ 定义了从原点到点的方向.
**** Aliasing[别名]
     对任何极坐标中的点,都可以用无数个成对的极坐标来描述它.这种现象被叫做 *aliasing*.如果两个极坐标
数值不同却表示同一个点,就表明两个互为另一个的 *别名*[aliases].需要注意的是在笛卡尔坐标系中的点是不
存在别名的,因为点和坐标是一一对应的关系.
     在此举一个简单的例子,假设极坐标中存在坐标$(r,\theta)$,则它可能的 *别名* 有$(r,k360^{\circ} + \theta)$,其中 $k$ 是整
数.当 $r<0$ 的时候,被解释成向与轴相反的方向移动.
     再进一步,其实 $+180^{\circ}$ 和 $-180^{\circ}$ 表示的是相同的方向.则有:
     $(r,\theta) = ((-1)^{k}r,(\theta + k180^{\circ})$
     经过上述表达式,我们已经知道了如何在2D极坐标空间中表示任意的点.但是由于 *aliasing* 的存在,为了
避免麻烦,我们必须要一个统一的标准来规范极坐标上的点.于是规定如下:
     $(r,\theta),{r \ge 0,-180^{\circ} < \theta \le 180^{\circ}$ 
     1. 如果 $r=0$ , 则令 $\theta = 0$.
     2. 如果 $r < 0$ , 则取 $-r$ ,再让 $\theta + 180^{\circ}$.
     3. 如果 $\theta \le -180^{\circ}$ , 则让 $\theta + 360^{\circ}$ 直到 $\theta > -180^{\circ}$.
     4. 如果 $\theta > 180^{\circ}$ , 则让 $\theta -360^{\circ}$ 直到 $\theta \le 180^{\circ}$.
**** Converting between Cartesian and Polar Coordinates in 2D[2D下笛卡尔与极坐标的转换]
     2D下极坐标用 $(r,\theta)$ 表示,笛卡尔坐标用 $(x,y)$ 表示.
     _从极坐标转换到笛卡尔坐标很简单,根据三角函数的性质,有:_
     $x = rcos\theta, y = rsin\theta$.
     棘手的是从笛卡尔坐标转换到极坐标.
     首先考虑 $r$ 的转换,通过勾股定理,可得:
     $r = \sqrt{x^{2}+y^{2}}$.
     很明显这里 $r \ge 0$,不需要再考虑对 $r$ 进行 *标准化*[canonical]了.
     其次考虑 $\theta$ 的转换,很明显有:
     $\frac{y}{x} = \frac{sin\theta}{cos\theta} = tan\theta, \theta = arctan(y/x)$.
     这里有两个问题,一是 $x \neq 0$ ,二是存在 $arctan\theta,\theta \in [-90^{\circ},+90^{\circ}]$.
     由于 $x = 0$ 时,除法未定义,所以不能运算.而 $y/x$ 由于符号取值问题,会产生四种可能.现在我们来总结下
可能的情况:
     \begin{equation*}
     atan2(y,x) = 
     \begin{cases}
     0, & x=0,y=0, \\
     +90^{\circ}, & x=0, y>0, \\
     -90^{\circ}, & x=0,y<0, \\
     arctan(y/x), & x>0, \\
     arctan(y/x)+180^{\circ}, & x<0,y\ge 0, \\
     arctan(y/x)-180^{\circ}, & x<0,y < 0. \\
     \end{cases}
     \end{equation*}
     需要注意的是, $atan2$ 这个函数的参数是 *反*[reverse]的.另一个要注意的是,在很多 *库*[library]里,
$atan2$ 在原点 $(0,0)$ 是未定义的.但是在本书中,我们定义 $atan2(0,0) = 0$.
     _至此,从笛卡尔坐标到极坐标的转换也已经完成,有:_
     $r = \sqrt{x^{2}+y^{2}},\theta = atan2(y,x)$.
*** 7.2 Why Would Anybody Use Polar Coordinates?[为什么有人要用极坐标]
    其实我们在日常生活中就经常使用极坐标:),比如有人问你的老家在哪儿,你告诉他,在双流的东南方,大概距
双流15公里,其实在这段话里,双流(表示原点),东南方(-45°),15公里(距离r)已经是在运用极坐标了.
    而在游戏里,我们经常在操控摄像头/使用武器等转向目标时,都需要采用极坐标.最厉害的是在追踪方面,通常
使用极坐标都是最好的选择.(先转向再移动,边移动边转向,最终都能直面目标).
    还有一个必须要讲的,采用极坐标而不是笛卡尔坐标的情况: _在一个球面上移动_.参考地球自身,其实我们的
*经度*[longtitude], *纬度*[lantitude] 就是采用的极坐标系,更准确的来说,是某种3D极坐标系- *球型坐标*
[sphere coordinates].
*** 7.3 3D Polar Space[3D极坐标空间]
    3D极坐标系的一个有意思的地方在于,我们知道当坐标从2D到3D,肯定会多一个参数,那么到底多出来的参数是
表示什么?是另一个 *距离* $r$ 还是另一个 *方向* $\theta$ ?
    事实是,3D极坐标空间有两种形态,
    一种是 *圆柱型坐标*[cylindrical coordinates],多出来的参数是另一个距离$r$.表示为:
    $(r,\theta,z)$
    另一种是 *球型坐标*[spherical coordinates],多出来的参数是另一个角度$\theta$.表示为:
    $(r,\theta,\phi)$
**** Cylindrical Coordinates[圆柱型坐标]
     要构造一个圆柱型坐标,分两步:
     1.) 构造一个2D极坐标,形成一个平面.
     2.) 过2D平面的原点作一条轴垂直于平面,命名为z轴.
     这样我们就可以将任意圆柱空间内的点表示为 $(r,\theta,z)$.而圆柱坐标系与笛卡尔坐标系的转换也非常简单.
参考之前2D的转换,再加上在z轴的表示上,两者是相同的,因而很简单.
**** Spherical Coordinates[球型坐标]
     相较于圆柱型坐标,球型坐标更为常见.同样的,我们来考虑如何构建一个球型坐标系.
     1.) 想象自己站在原点,面对水平方向上的极坐标轴,垂直方向上的极坐标轴是从你的脚指向你的头.
     再将你的右手臂打直,和水平方向的轴保持同一方向.
     2.) 逆/顺时针旋转 $\theta$.
     3.) 将你的右手臂上下旋转 $\phi$.
     4.) 从原点沿着方向移动距离$r$.
     水平方向上的角 $\theta$ 被叫做 *方位角*[azimuth], $\phi$ 被叫做 *天顶角*[zenith].
**** Some Polar Conventions Useful in 3D Virtual Worlds[虚拟3D世界中一些有用的极坐标设定]
     前面提到的球型坐标系是传统的右手坐标系统.在此系统下笛卡尔坐标系与球型坐标系的转换非常的简洁.然
而,对真正在游戏行业工作的人来说,这个系统带来的麻烦远大于给予的好处:
     - 默认的水平方向 $\theta = 0$ 指向的是 $+x$ .因为在大多数人的眼中,  *默认* 水平方向并不会让人联想到 *右手*
或者 *东*.
     - 从某些方面来看,使用 $\phi$ 并不合适.从2D扩展到3D时第一个要考虑的就是新增的 $\phi$ 的初始值问题,而让人
尴尬的是令 $\phi = 0$ 将导致一个问题 - *Gimbal lock*[万向节死锁].相反,我们让这个点在2D平面中表示为
$(r,\theta,90^{\circ})$.
     - $\theta$ 和$\phi$ 需要一定的时间去适应.$r$ 还有,至少能直观的让人知道表示 *半径*[radius].
     - 如果 *球型坐标* 的前两个角能和 *欧拉角*[Euler angless]一样的话就爽了. *欧拉角* 主要用来表示3D中
的方向.(第八章就知道欧拉角是什么了:))
     - 这是个 *右手坐标系*,而我们在这里使用 *左手坐标系*.(异端啊)

     在我们定义的 *球型坐标系* 里, $r$ 继续保留原意使用.至于另外两个角则需要重新命名和调整.
     水平方向上的角被重命名为 $h$ , *heading*[头],默认为0时表示方向为 *forward* 或者是 *to the north*.
考虑到我们采用的是 *左手坐标系*, $h$ 对应的是笛卡尔坐标系的 $+z$ 轴.同样原因,选取 *顺时针*[clockwise]
为旋转正方向.
     垂直方向上的角被重命名为 $p$, *pitch*[倾斜角],主要用于测量向上/向下看的角度的大小.
     默认当 $pitch = 0$ 时表示指向水平方向.默认的正方向时 *向下*[downward]的,表示在测量 *偏角*
[angle of declination].向下为正可能让人觉得有点不符合直觉,但是确是与左手坐标系的规则吻合的.
**** Aliasing of Spherical Coordinates[球型坐标的混叠]
     在2D极坐标的时候我们就讨论过坐标 *混叠*[aliasing]问题,一个空间中的点可以由多个坐标来表示.在3D
中一样有这个问题.
     第一个肯定能解决混叠的方法就是给每个轴加一个 $\times 360^{\circ}$.很明显这不是一个优雅的解决方案.
     另外两个解决方案很有意思,因为它们是由坐标的互相依赖引起的.换句话说就是, $r$ 的含义是通过角的值来
确定的.这种依赖关系造成了 *混叠* 和 *奇点*[fn:singularity]:
     - 在2D中出现 *混叠* 时,可以通过让 $r$ 取负和调整 $\theta$ 值来解决.同样在3D中我们也可以通过让奇数值 $\times$
180° 来表示反转 *heading*,再对 *pitch* 取负.
     - 在2D中奇点出现在 $r=0$ 时,因为这个时候角坐标无法确定值.同样在3D中,当 $r=0$ 时两个角也无法确
定值.
    由于 $r$ 的变化取决于角的值,所以球型坐标系统一样会产生 *混叠* 问题.然而更坑的是,它还有遇到另外一个
*混叠* 问题.由于 *pitch* 角围绕轴的旋转取决于 *heading* 角,这就造成了另一种 *混淆* 和 *奇点*.
     - 就算排除掉各自独立的角的混叠,不同的 *heading* 和 *pitch* 值也能得到相同的 *方向*[direction].
       $(h,p)$ 可以被表示为 $(h \pm 180^{\circ}, 180^{\circ} - p)$.
     - *奇点* 出现在 *pitch* 等于 $\pm 90^{\circ}$ 的时候.这种情况被叫做 *Gimbal lock*[万向节死锁],方向总是完全垂
直并且 *heading* 角已经 *不相关*[irrelevant].(但是这个问题我们还是等到第八章再说:)).
     在2D极坐标的时候我们就定义了一个 *标准球型坐标*[canonical spherical coordinates].在3D球型坐标中,
$r,h$ 还是同之前定义一样,而 *pitch* 则添加了两个限制条件.
     第一是 *pitch* 的值限定在 $[-90^{\circ},+90^{\circ}]$.
     第二是当出现 *Gimbal lock* 的时候, 由于 *pitch* 取到了极值, *heading* 值将变得 *不相关*,所以这种
情况下我们强制让 $h=0$.
     现在我们列出 _满足标准球型坐标的情况_:
     $r\ge 0$
     $-180^{\circ} < h \le 180^{\circ}$
     $-90^{\circ} \le p \le 90^{\circ}$
     $r=0, \Rightarrow  h=p=0$
     $|p| = 90^{\circ} \Rightarrow h=0$
     下面是 _如何将一个非标准坐标转换到标准坐标的算法_:
     1. if $r=0$,then assign $h=p=0$.
     2. if $r<0$,then negate $r$,add $180^{\circ}$ to $h$ ,and negate $p$.
     3. if $p < -90^{\circ}$,then add $360^{\circ}$ to $p$ until $p \ge -90^{\circ}$.
     4. if $p > 270^{\circ}$,then subtract $360^{\circ}$ unitl $p \le 270^{\circ}$.
     5. if $p > 90^{\circ}$,then add $180^{\circ}$ to $h$ and set $p = 180^{\circ} -p$ .
     6. if $h \le -180^{\circ}$,then add $360^{\circ}$ to $h$ until $h > -180^{\circ}$ .
     7. if $h > 180^{\circ}$,then subtract $360^{\circ}$ from $h$ until $h \le 180^{\circ}$ .
**** Converting between Spherical and Cartesian Coordinates[球型坐标与笛卡尔坐标的相互转换]
     从 _球形坐标系转换到笛卡尔坐标系_,先讨论传统意义上的使用 *右手坐标系* 的情况.
     我们首先要考虑的是已知的参数:$(r,\theta,\phi)$.一个是长度,两个是角度.
     而真正的问题在于如何表示 $(x,y,z)$.三个参数都是长度.
     根据勾股定理,一个很明显的公式是 $\sqrt{x^{2}+y^{2}+z^{2}} = r$,在此考虑将水平平面上的值 $\sqrt{x^{2}+y^{2}$ 
用 $d$ 表示,则有 $d = \sqrt{x^{2}+y^{2}}$.
     再根据两个角度 $(\theta,\phi)$ 来表示 $(x,y,z)$ 的值,有:
     $z/r = cos\phi, z = rcos\phi$ .
     剩下的就是如何计算 $x,y$ 了.现在先考虑 $\phi = 90^{\circ}$ 的情况.在这种情况下,3D极坐标空间就变成了一个
2D极坐标空间.假设 $x^{'},y^{'}$ 分别为$x,y$ 在 $\phi = 90^{\circ},d=r$ 下的结果,那么我们有:
     $x^{'} = rcos\theta,y^{'} = rsin\theta$.

     根据相似三角形的性质,有 $x/x^{'} = y/y^{'} = d/r$,而同时 $d/r = sin\phi$ .由此可得:
     $x = rsin \phi cos \theta, y = rsin \phi sin\theta, z = rcos \phi$.
     而由于这个是 *右手坐标系* 下的情况,我们将其带换为对应的 *左手坐标系*:
     $x = r cos(p) sin(h), y = -rsin(p), z = rcos(p)cos(h)$.

     _于是,当从球形坐标系转换到笛卡尔坐标系时,有:_
     $(x,y,z) \Rightarrow x = r cos(p) sin(h), y = -rsin(p), z = rcos(p)cos(h)$

     由于 *混叠* 的原因,从 _笛卡尔坐标到球型坐标_ 的转换更为复杂.
     在2D极坐标系中,$r = \sqrt{x^{2}+y^{2}+z^{2}}$.
     在 $r=0$ 时,奇点位于原点,算是一种特殊情况.
     至于 $h$,使用atan2可以直接得出:
     $h = atan2(x,z)$.
     由之前的等式可知, 
     $y = -rsin(p),-y/r = sin(p),p = arcsin(-y/r)$.

     _于是,当从笛卡尔坐标转换到球型坐标时,有:_
     $(r,h,p) \Rightarrow r = \sqrt{x^{2}+y^{2}+z^{2}}, h = atan2(x,z),p = arcsin(-y/r)$.
*** 7.4 Using Polar Coordinates to Specify Vectors[使用极坐标系来确定向量]
    我们已经知道了如何在极坐标系中描述一个 *点*,也知道怎么在笛卡尔坐标系中描述一个 *向量*.同样,我
们也可以在极坐标系中描述一个向量.极坐标具有的两种类型的参数, *方向* 和 *长度*,原本就是向量自身的
属性.
    所以说,实际上极坐标所做的,就是直接描绘向量.而笛卡尔坐标系中反而采用了一种间接的方法来表示向
量.当我们讨论如何使用极坐标时,实际生活中不知道已经使用了多少次."在你的右前方5米的地方",诸如此类.
    同样我们也已经知道如何在数学上完成向量在笛卡尔坐标和极坐标的转换.因为转换 *点* 的技巧可以原封
不动用在 *向量* 身上.
* Footnotes

[fn:singularity] 在数学中,表示 _数学物件中无法处理的点_.

[fn:surfacenormal] 三维平面的法线是 _垂直_ 于该平面的 *三维向量*.法线是与多边形的曲面垂直的理论线.

[fn:worldspace] 在南方人/北方人指路的时候,北方人往往告诉你,往北面/南面走,而南方人则是沿着这儿到
下个路口往左/往右,可见北方人采用的世界坐标系,而南方人采用的是对象坐标系.

[fn:norm] 
要更好的理解范数,就要从 _函数、几何与矩阵_ 的角度去理解,我尽量讲的通俗一些。
我们都知道,函数与几何图形往往是有对应的关系,这个很好想象,特别是在三维以下的空间内,
函数是几何图像的数学概括,而几何图像是函数的高度形象化,比如一个函数对应几何空间
上若干点组成的图形。
但当函数与几何超出三维空间时,就难以获得较好的想象,于是就有了 *映射* 的概念,映射表达
的就是 _一个集合通过某种关系转为另外一个集合_
通常数学书是先说映射,然后再讨论函数,这是因为 _函数是映射的一个特例_,为了更好的在数学
上表达这种映射关系,（这里特指线性关系）于是就引进了矩阵。
这里的矩阵就是表征上述空间映射的 *线性关系*. 而通过向量来表示上述映射中所说的这个集合,
而我    们通常所说的 *基* ,就是这个集合的最一般关系。
于是,我们可以这样理解,一个集合（向量）,通过一种映射关系（矩阵）,得到另外一个几何（另外
一个向量）。
那么向量的范数，就是表示这个 _原有集合的大小_ 。
而矩    阵的范数,就是表示这个 _变化过程的大小的一个度量_ 。
那么说到具体    几几范数，其不过是定义不同,一个矩阵范数往往由一个向量范数引出,我们称之为
*算子范数*,其物理意义都如我上述所述。
0范数,向量中非零元素的个数
1范数,为绝对值之和
2范数,就是通常意义上的模
无穷范数,就是取向量的最大值
